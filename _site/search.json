[
  {
    "objectID": "gymnasium.html",
    "href": "gymnasium.html",
    "title": "\nGymnasium\n",
    "section": "",
    "text": "Gymnasium\n\nJan 12, 2024\n\n\nEnv"
  },
  {
    "objectID": "rl.html",
    "href": "rl.html",
    "title": "\nCS 443\n",
    "section": "",
    "text": "CS 443\n\nNov 22, 2023\n\nAll notes are based on the course at UIUC CS 443 taught by professor  Nan Jiang (ÂßúÊ•†).\nAs a senior Computer Science student embarking on the CS 443 course on Reinforcement Learning, I am filled with a sense of purpose and enthusiasm. This course, guided by Professor Nam Jiang, represents not just a pivotal point in my academic journey but also an opportunity to create a valuable resource for future students who will navigate the complexities of this advanced field. My decision to take this course in the upcoming semester is driven by a fascination with the dynamic and impactful world of RL. I understand the challenges that lie ahead, having encountered rigorous coursework in my academic path, but my commitment to delving deeper into Reinforcement Learning is unwavering. I am motivated not only by my desire to expand my own understanding but also by the prospect of aiding others in comprehending and appreciating the intricacies of this cutting-edge area of computer science.\n\nMathematics\n\nSome notes on mahtematics see HERE! \n\nGymnasium\n\nSome notes on a RL environment see HERE! \n\n\nThe Plan\n\n\n\nDAgger\n\nMDP Notes\n\nIntroduction\n\nNotes\n\nMarkov Decision Process formulation\n\nMDP Notes\n\nValue function\n\nValue Notes\n\nBellman equation\n\nBellman equation Notes\n\nOptimality\n\noptimality Notes\n\nValue Iteration\n\nValue iteration Notes\n\n\n\n  Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child‚Äôs? If this were then subjected to an appropriate course of education one would obtain the adult brain.  ‚Äî Alan Turing\nYou insist that there is something a machine cannot do. If you tell me precisely what it is a machine cannot do, then I can always make a machine which will do just that.  ‚Äî John von Neumann"
  },
  {
    "objectID": "mdp.html",
    "href": "mdp.html",
    "title": "\nMarkov decision process\n",
    "section": "",
    "text": "Markov decision process\n\\[\n\\def\\emph#1{\\textit{#1}}\n\\]\nIn reinforcement learning, the interactions between the agent and the environment are often described by a state space \\(\\mathcal{S}\\), action space \\(\\mathcal{A}\\), transition function \\(P : \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\Delta(\\mathcal{S})\\); where \\(\\Delta(\\mathcal{S})\\) is the space of probability distributions over \\(\\mathcal{S}\\) (i.e., the probability simplex). \\(P(s^\\prime \\mid s, a)\\) is the probability of transitioning into state \\(s^\\prime\\) upton taking action \\(a\\) in state \\(s\\). A reward function \\(R : \\mathcal{S} \\times \\mathcal{A} \\rightarrow [0, R_{max}]\\). where \\(R_{max} &gt; 0\\) is a constant. \\(R(s, a)\\) is the immediate reward associated with taking action \\(a\\) in state \\(s\\). A discount factor \\(\\gamma \\in [0, 1)\\) , which defines the horizon for the problem."
  },
  {
    "objectID": "mdp.html#opengym",
    "href": "mdp.html#opengym",
    "title": "\nMarkov decision process\n",
    "section": "OpenGym",
    "text": "OpenGym\n\nInitialize the Environment\nimport gym \nenv = gym.make('MountainCar-v0')\n\n\nMountain car\nIn the Mountain Car Markov Decision Process (MDP), a car is randomly positioned at the lowest point of a sinusoidally-shaped valley. This MDP operates deterministically, providing a set of possible accelerative actions that can be executed to move the car either forward or backward. The objective is to judiciously use these accelerations to navigate the car to the target location, situated at the peak of the hill to the right. Within the gym framework, the mountain car scenario comes in two variants: one allowing for a discrete set of actions, and the other permitting a continuum of actions. The variant in question here is the one that employs discrete actions.\nclass MountainCarEnv(gym.Env):\n    def __init__(self, render_mode: Optional[str] = None, goal_velocity=0):\n        self.min_position = -1.2\n        self.max_position = 0.6\n        self.max_speed = 0.07\n        self.goal_position = 0.5\n        self.goal_velocity = goal_velocity\n\n        self.force = 0.001\n        self.gravity = 0.0025\n\n        self.low = np.array([self.min_position, -self.max_speed], dtype=np.float32)\n        self.high = np.array([self.max_position, self.max_speed], dtype=np.float32)\n\n        self.render_mode = render_mode\n\n        self.screen_width = 600\n        self.screen_height = 400\n        self.screen = None\n        self.clock = None\n        self.isopen = True\n\n        self.action_space = spaces.Discrete(3)\n        self.observation_space = spaces.Box(self.low, self.high, dtype=np.float32)"
  },
  {
    "objectID": "algorithms.html",
    "href": "algorithms.html",
    "title": "\nCS 374\n",
    "section": "",
    "text": "CS 374\nAs a senior Computer Science student creating this resource, I felt a deep sense of responsibility not just towards my own academic growth but also for the benefit of future students grappling with the complexities of the renowned CS 374 algorithms course. My journey through this course, taught by Professor Erickson during the Fall 2023 semester, was challenging. Despite struggling significantly with the material, I was driven by a desire to immerse myself more deeply in the subjects taught.\nThis endeavor is not just an exercise in comprehension but a step towards mastery. By diving into and clearly explaining the course content, I‚Äôm hoping to deepen my understanding and get more comfortable with these complex ideas. My hope is that this process will not only aid my own progression in computer science but also serve as a valuable guide for others on a similar path. Please see  Jeff‚Äôs website and  Jeff‚Äôs book as his book is freely available online.\nSome notes on data structures HERE!"
  },
  {
    "objectID": "algorithms.html#coursework",
    "href": "algorithms.html#coursework",
    "title": "\nCS 374\n",
    "section": "Coursework",
    "text": "Coursework\n\nSection 1\n\nString induction\n\nLab1a: String induction\n\nLanguages and regular expressions\n\nLab1b: Regular expressions\n\nDFAs: intuition, definition, examples\n\nLab2a: DFAs\n\nDFAs: product construction, closure, automatic=regular\n\nLab2b: DFA product construction\n\nProving nonregularity via fooling sets; NFAs: intuition and examples \n\nLab3a: Proving nonregularity\n\nNFAs; Œµ-transitions, equivalence with DFAs\n\nLab3b: Regular expression to NFA to DFA (to regular expression)\n\nLanguage transformations\n\nLab4a: Language transformations\n\nContext-free languages and grammars \n\nLab4b: Context-free languages and grammars\n\nTuring machines \n\nLab5a: More language transformations\n\n\n\n\nSection 2\n\nRecursion: Hanoi, mergersort, quicksort\n\nLab6a: Binary search\n\nDevide and conquer: selection, multiplication\n\nLab6b: Fun with Karatsuba\n\nBactracking: n queens, game trees, text segmentation\n\nLab7a: Backtracking\n\nDynamic programming: Fibonacci, text segmentation again\n\nLab7b: Dynamic programming\n\nSequence dynamic programming: Edit distance \n\nLab8a: More dynamic programming\n\nTree-shaped dynamic programming: Carpentry\n\nLab8b: Return of the son of revenge of dynamic programming\n\nGraphs: definitions, representations, data structures, traversal\n\nLab9a: Graph modeling\n\nDepth-first search, topological sort \n\nLab9b: Topological sort\n\nDAG DP, strong components; generic shortest paths, BFS, DFS, and Dijkstra \n\nLab10a: Shortest paths\n\nShortest paths via Dijkstra and Bellman-Ford \n\nLab10b: All-pairs shortest paths\n\nBellman-Ford again and Floyd-Warshall \n\nLab11a: Solve it both ways\n\n\n\n\nSection 3\n\nReductions: Cliques and friends, Hamiltoninan cycles\n\nLab12a: Reductions\n\nP vs NP, NP-hardness, 3SAT, reduction to max independent set\n\nLab12b: NP-hardness proofs\n\nNP-harness: Vertex cover to Hamiltoninan cycle\n\nLab13a: More NP-hardness proofs\n\nNP-harness: Why bother, Choosing which problem to reduce from\n\nLab13b: Even more NP-hardness proofs\n\nUndecidability: code is data, the halting problem \n\nLab14a: Yet even still more NP-hardness practice\n\nUndecidability: reductions and Rice‚Äôs theorem\n\nLab14b: Using Rice‚Äôs Theorem\nLab14c: Undecidability Reductions\n\n\n\n  I propose to consider the question, ‚ÄúCan machines think?‚Äù  ‚Äî Alan Turing, ‚ÄúComputing Machinery and Intelligence‚Äù (1950)\nIf you find that you‚Äôre spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that you‚Äôre spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice.  ‚Äî Donald Knuth\nPremature optimization is the root of all evil.  ‚Äî Donald Knuth, ‚ÄúStructured Programming with Go To Statements‚Äù (1974)\nYoung man, in mathematics you don‚Äôt understand things. You just get used to them.  ‚Äî John von Neumann\nDealing with failure is easy: Work hard to improve. Success is also easy to handle: You‚Äôve solved the wrong problem. Work hard to improve.  ‚Äî Alan Perlis, ‚ÄúEpigrams on Programming‚Äù (1982)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "\nAbout\n",
    "section": "",
    "text": "About\n\n\nSee my  website \nThis blog was largerly motivated by  Andrej Karpathy  and a personal professor at the University of Illinois at Urbana-Champaign  Jeff Erickson."
  },
  {
    "objectID": "lab7b.html",
    "href": "lab7b.html",
    "title": "\nDymamic programming\n",
    "section": "",
    "text": "Dymamic programming\nNov 22, 2023\nHow long is the longest increasing subsequence?\n4 1 2 7 6 5 8 9 3   1 2 6 8 9\nLets define a couple defintions to fromulate this:"
  },
  {
    "objectID": "lab7b.html#visulization-of-sequence",
    "href": "lab7b.html#visulization-of-sequence",
    "title": "\nDymamic programming\n",
    "section": "Visulization of sequence",
    "text": "Visulization of sequence\n\n\nCode\nlibrary(ggplot2)\n\n# Your original sequence\nsequence &lt;- c(4, 1, 2, 7, 6, 5, 8, 9, 3)\n\n# The known LIS\nlis &lt;- c(1, 2, 7, 8, 9)\n\n# Create a data frame for the original sequence\ndata &lt;- data.frame(x = 1:length(sequence), y = sequence)\n\n# Identify the indices of the LIS in the original sequence\nlis_indices &lt;- match(lis, sequence)\n\n# Create a data frame for the LIS\nlis_data &lt;- data.frame(x = lis_indices, y = lis)\n\n# Plotting the sequence and the LIS\nggplot(data, aes(x, y)) + \n  geom_point() + \n  geom_line(color = \"gray\") +\n  geom_point(data = lis_data, aes(x, y), color = \"red\") +\n  geom_line(data = lis_data, aes(x, y), color = \"red\") +\n  scale_x_continuous(breaks = 1:length(sequence)) +  \n  scale_y_continuous(breaks = 1:max(sequence)) +  \n  labs(x = \"Index\", y = \"Value\", title = \"Sequence with Highlighted LIS 1 2 7 8 9\")\n\n\n\n\n\n\n\n\nFigure¬†1: Plot of the sequence with the highlighted LIS 1 2 7 8 9\n\n\n\n\n\nThere could be multiple subsequences but we only care about the maximum increasing subsequence.\n\nHere is my animated plot:\n\n\n\nAnimated Plot\n\n\n\nDymamic programming\n\n\nDescribe and analyze dynamic programming algorithms for the following longest-subsequence problems.\n\nGiven an array \\(A[1...n]\\) of integers, compute the length of a longest increasing subsequence of \\(A\\)."
  },
  {
    "objectID": "ramsey3.html",
    "href": "ramsey3.html",
    "title": "\nRamsey Theory\n",
    "section": "",
    "text": "Ramsey Theory\n\nJan 13, 2024\n\nMy interest in Ramsey Theory, a fascinating field that explores the emergence of patterns within sufficiently large systems, was sparked by my exploration of topics in graph theory. I was looking to learn about order from choas I started with the example of the pigeonhole principle\n\nTheorem (Pigeonhole Princicple)\n\nIf there exists \\(m\\) pigeonoles containing \\(n\\) pigeons, where \\(n &gt; m\\), then at least one of the pigeonholes must contain at least 2 pigeons."
  },
  {
    "objectID": "lab1a.html",
    "href": "lab1a.html",
    "title": "\nString Induction\n",
    "section": "",
    "text": "String Induction\n\nNov 22, 2023"
  },
  {
    "objectID": "DavidMarr.html",
    "href": "DavidMarr.html",
    "title": "\nDMT\n",
    "section": "",
    "text": "DMT\n\n\nHow do we build intelligent machines?\n\n\nComing Soon!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jorge Velez",
    "section": "",
    "text": "I drink a lot of coffee and I try to be a better computer scientist over time. ‚òï üåé üåå This blog serves as an information space focusing on areas that interest me and that I would like to research..\n\nSorry for any delays, broken links, and ugly layouts; still working on finishing this up."
  },
  {
    "objectID": "index.html#hello-world",
    "href": "index.html#hello-world",
    "title": "Jorge Velez",
    "section": "",
    "text": "I drink a lot of coffee and I try to be a better computer scientist over time. ‚òï üåé üåå This blog serves as an information space focusing on areas that interest me and that I would like to research..\n\nSorry for any delays, broken links, and ugly layouts; still working on finishing this up."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jorge Velez",
    "section": "Education",
    "text": "Education\n University of Illinois at Urbana-Champaign | Bachelros of Science in Computer Science | Aug 2022 - Dec 2024\n Atttend my local community college to study computer science and mathematics | Agust 2021 - May 2022"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jorge Velez",
    "section": "Experience",
    "text": "Experience\n Argonne National Lab | GPU AI Research | May 2024 - August 2024\n Argonne National Lab | Deep Graph NN Chemistry Research | May 2022 - August 2022"
  },
  {
    "objectID": "cs.html",
    "href": "cs.html",
    "title": "\nComputer Science\n",
    "section": "",
    "text": "Computer Science\n\n\nFeb 18, 2024 SYCL\nJan 16, 2024 Statistics and Probability 2 Notes dedicated to Stat 410\nJan 15, 2024 Database Systems Notes dedicated to CS 411\nJan 12, 2024 Ramsey Theory Order From Chaos\nNov 22, 2023 Progrmg Languages & Compilers Notes dedicated to CS 421\nDec 31, 2023 Neural Networks Initially, neural networks were met with skepticism. However, a dedicated few persevered, pushing the boundaries of artificial intelligence. Their relentless pursuit and innovation turned a once-doubtful idea into a groundbreaking reality. Today, their work stands as a testament to human ingenuity, having significantly transformed technology and our understanding of machine learning.\nDec 31, 2023 The story of out time Llama2: Open Foundation and Fine-Tuned Chat Models.‚Äù This post offers a comprehensive and engaging analysis of LLMs, starting from their foundational concepts to their complex mechanisms of learning from extensive datasets to mimic human language. We delve into the intricacies of the Llama2 model, discussing its innovative approaches in open foundation training and the nuances of its fine-tuning for chat applications. Our journey through this post not only highlights the transformative impact of LLMs across various sectors but also addresses the ethical dilemmas and potential future advancements in this field.\nDec 31, 2023 P vs NP computational complexity in the heavens The P vs NP problem, often regarded as the most significant unresolved issue in theoretical computer science, is one of the seven Millennium Prize Problems identified by the Clay Mathematics Institute, offering a reward of one million dollars for a conclusive proof or disproof. In simple terms, ‚ÄòP‚Äô represents a category of problems that are comparatively easy to solve, whereas ‚ÄòNP‚Äô encompasses problems that are, on the surface, extremely challenging. If P were equal to NP, it would suggest that these seemingly difficult problems actually have straightforward solutions. However, the intricacies of this concept are more complex.\n\nFinance\n\n\nFeb 12, 2024 Game Theory John Von Neumann\n\nThe Art of Computer Programming\n\n\n\\(\\infty\\) Donald Knuth My study and notes on Donald Knuths work on algorithms.\nComing soon!"
  },
  {
    "objectID": "cs421.html",
    "href": "cs421.html",
    "title": "\nCS 421\n",
    "section": "",
    "text": "CS 421\n\n\n\nBasic OCaml Programming"
  },
  {
    "objectID": "lab8a.html",
    "href": "lab8a.html",
    "title": "\nEdit distance\n",
    "section": "",
    "text": "Edit distance\n\n\n\nThe minimum number of character insertions, deletions, and substitutions needed to convert one string into another is known as the edit distance between those two strings.\nGiven two strings word1 and word2, return the minimum number of operations required to convert word1 to word2.\nYou have the following three operations permitted on a word:\n\nInsert a character\nDelete a character\nReplace a character"
  },
  {
    "objectID": "dataStructures.html",
    "href": "dataStructures.html",
    "title": "\nData Strcutures\n",
    "section": "",
    "text": "Data Strcutures\n\nDec 31, 2023\n\n\nLinked List: notes\nHash Table: notes\nBinary Tress\nRandom Binary Search Trees\nRed-Black Trees\nHeaps\nSorting algorithms: notes\nGraph: notes\nExternal Memory Searching"
  },
  {
    "objectID": "linearAlgebra.html",
    "href": "linearAlgebra.html",
    "title": "\nLinear Algebra\n",
    "section": "",
    "text": "Linear Algebra\n\nJan 15, 2024\n\n Vector spaces\nA vector space \\(V\\) is a set, the elements of which are called \\(\\textbf{vectors}\\), on which two operations are defined: vectors can be added together, and vectors can be multiploed by real numbers (\\(\\textbf{scalars}\\)).\nWith this \\(V\\) must statisfy the following:\n\nThere exists an additive identity \\(\\mathbf{0}\\) in \\(V\\) such that \\(\\mathbf{x} + \\mathbf{0} = \\mathbf{x}\\) for all \\(\\mathbf{x} \\in V\\)\nFor each \\(\\mathbf{x} \\in V\\), there exists and additive inverse, \\(-\\mathbf{x}\\), such that \\(\\mathbf{x} + (-\\mathbf{x}) = \\mathbf{0}\\)\nThere exists a multiplicative identity (written 1) in \\(\\mathbb{R}\\) such that \\(1\\mathbf{x} = \\mathbf{x}\\) for all \\(\\mathbf{x} \\in V\\)\nCommutativity: \\(\\mathbf{x} + \\mathbf{y} = \\mathbf{y} + \\mathbf{x}\\) for all \\(\\mathbf{x}, \\mathbf{y} \\in V\\)\nAssociativity: \\((\\mathbf{x} + \\mathbf{y}) + \\mathbf{z} = \\mathbf{x} + (\\mathbf{y} + \\mathbf{z})\\) and \\(\\alpha(\\beta \\mathbf{x}) = (\\alpha\\beta)\\mathbf{x}\\) for all \\(\\mathbf{x}, \\mathbf{y}, \\mathbf{z} \\in V\\) and \\(\\alpha, \\beta \\in \\mathbb{R}\\)\nDistributivity: \\(\\alpha(\\mathbf{x} + \\mathbf{y}) = \\alpha\\mathbf{x} + \\alpha\\mathbf{y}\\) and \\((\\alpha + \\beta)\\mathbf{x} = \\alpha\\mathbf{x} + \\beta\\mathbf{x}\\) for all \\(\\mathbf{x}, \\mathbf{y} \\in V\\) and \\(\\alpha, \\beta \\in \\mathbb{R}\\)\n\nA set of vectors \\(\\mathbf{v}_1, \\cdots, \\mathbf{v}_n \\in V\\) is said to be \\(\\textbf{linearly independent}\\) if\n\\[\n    \\alpha \\mathbf{v}_n + \\cdots + \\alpha_n\\mathbf{v}_n = \\mathbf{0} \\quad \\text{ imlpies } \\quad\\alpha_1 = \\cdots = \\alpha_n = 0.\n\\]\nThe \\(\\textbf{span}\\) of \\(\\mathbf{v}_1, \\cdots, \\mathbf{v}_n \\in V\\) is the set of all vectors that can be expressed of a linear combination of them:\n\\[\n    \\text{span}\\{\\mathbf{v}_1, \\cdots, \\mathbf{v}_n\\} = \\{\\mathbf{v} \\in V : \\exists\\alpha, \\cdots, \\alpha_n \\text{ such that } \\alpha\\mathbf{v}_1 + \\cdots + \\alpha_n\\mathbf{v}_n = \\mathbf{v}\\}\n\\]\nIf the set of vectors is linearly independent and its span is the whole \\(V\\), those vectors are said to be a \\(\\textbf{basis}\\) for \\(V\\). In fact, every linear independent set of vectors forms a basis for its span.\nIf a vector space is spanned by a finite numbers of vectors, it is said to be \\(\\textbf{finite-dimensional}\\). Otherwise it is \\(\\textbf{infinite-dimensional}\\). The number of vectors in a basis for a finite-dimensional vector space \\(V\\) is called the \\(\\textbf{dimension}\\) of \\(V\\) and demoted dim \\(V\\).\n Euclidean space\nThe quintessential vector space is \\(\\textbf{Eculidean space}\\), which we denote \\(\\mathbb{R}^n\\). The vectors in this space consist of \\(n\\)-tuples of real numbers:\n\\[\n    \\mathbf{x} = \\left(x_1, x_2, \\cdots, x_n\\right)\n\\]\nIt is also useful to consider them as a \\(n \\times 1\\) matrices, or \\(\\textbf{column vectors}\\):\n\\[\n    \\mathbf{x} = \\begin{bmatrix}\n        x_{1} \\\\\n        x_{1} \\\\\n        \\vdots \\\\\n        x_{n}\n        \\end{bmatrix}\n\\]\nAddition and scalar multiplication are defined component-wise on vectors in \\(\\mathbb{R}^n\\). \\[\n    \\mathbf{x} + \\mathbf{y} = \\begin{bmatrix}\n        x_{1} + y{1} \\\\\n        x_{1} + y_{2}\\\\\n        \\vdots \\\\\n        x_{n} + y_{n}\n        \\end{bmatrix}, \\qquad \\alpha\\mathcal{x} = \\begin{bmatrix}\n                                                    \\alpha x_{1} \\\\\n                                                    \\vdots \\\\\n                                                    \\alpha x_{n}\n                                                    \\end{bmatrix}\n\\]\nEuclidean space is used to mathematically represent physical space, with notions such as distance, length, and angles. Although it becomes hard to visualize fot \\(n &gt; 3\\), these concepts generalize mathematically in obvious ways. Even when you‚Äôre wokring in more general settings than \\(\\mathbb{R}^n\\), it is often useful to visualize vector addition and scalalr multiplication in terms of \\(2D\\) vectors in the plane or \\(3D\\) vectors in space.\nSubspaces\nVector spaces can contain other vector spaces. If \\(V\\) is a vector space, then \\(\\mathcal{S} \\subseteq V\\) is said to be a \\(\\textbf{subspace}\\) of \\(V\\) if:\n\n\\(\\mathbf{0} \\in \\mathcal{S}\\)\n\\(\\mathcal{S}\\) is closed under addition: \\(\\mathbf{x}, \\mathbf{y} \\in \\mathcal{S}\\) implies \\(\\mathbf{x} + \\mathbf{y} \\in \\mathcal{S}\\)\n\\(\\mathcal{S}\\) is closed under scalar multiplication: \\(\\mathbf{x} \\in \\mathcal{S}, \\alpha \\in \\mathbb{R}\\) implies \\(\\alpha\\mathbf{x} \\in \\mathcal{S}\\)\n\nNote that \\(V\\) is always a subsapce of \\(V\\), as is the trivial vector space which contains only \\(\\mathbf{0}\\). As a concrete example, a line passing through the origin is a subsapce of Eculidean space. If \\(U\\) and \\(W\\) are subspaces of \\(V\\), then their sum is defined as\n\\[\n    U + W = \\{\\mathbf{u} + \\mathbf{w} \\mid \\mathbf{u} \\in U, \\mathbf{w} \\in W \\}\n\\]\nIf \\(U \\cap W = \\{\\mathbf{0}\\}\\), the sum is said to be a \\(\\textbf{direct sum}\\) and written \\(U \\oplus W\\). Every vector in \\(U \\oplus W\\) can be written uniquely as \\(\\mathbf{u} + \\mathbf{w}\\) for some \\(\\mathbf{u} \\in U\\) and \\(\\mathbf{w} \\in W\\).\nThe dimensions of sums of subspaces obey a friendly relationship:\n\\[\n    \\text{dim}(U + W) = \\text{dim } U + \\text{dim } W - \\text{dim}(U \\cap W)  \n\\]\nIt follows that\n\\[\n    \\text{dim}(U \\oplus W) = \\text{dim } U + \\text{dim } W\n\\]\nsince \\(\\text{dim}(U \\cap W) = \\text{dim}(\\{\\mathbf{0}\\}) = 0\\) if the sum is direct.\nLinear maps\n Matrices and transposes\n\n\\(A\\) is a \\(m \\times n\\) real matrix, wrtitten \\(A \\in \\mathbb{R}^{m \\times n}\\), if: \\[\nA = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\n\nwhere \\(a_{i, j} \\in \\mathbb{R}\\). The \\((i, j)\\)th entry of \\(A\\) is \\(A_{i, j} = a_{i, j}\\).\n\nThe transpose of \\(A \\in \\mathbb{R}\\) is define as: \\[\nA^{T} = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\n\nsuch that, \\((A^{T})_{i, j} = A_{j, i}\\)\nNote: \\(x \\in \\mathbb{R}^{n}\\) is considered to be a columnn vector in \\(\\mathbb{R}^{n \\times 1}\\)\nSums and products of matrcies \n\nThe sum of matrices \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(B \\in \\mathbb{R}^{m \\times n}\\) is the matrix \\(A + B \\in \\mathbb{R}^{m \\times n}\\) such that \\[\n  (A + B)_{i, j} = A_{i, j} + B_{i, j}\n\\]\nThe product of matrices \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(B \\in \\mathbb{R}^{n \\times \\ell}\\) is the matrix \\(AB \\in \\mathbb{R}^{m \\times \\ell}\\) such that\n\n\\[\n    (AB)_{i, j} = \\sum_{k=1}^n   A_{i, k} B_{k, j}\n\\]"
  },
  {
    "objectID": "mathematics.html",
    "href": "mathematics.html",
    "title": "\nMathematics\n",
    "section": "",
    "text": "Mathematics\n\nJan 15, 2024\n\n\nLinear Algebra: notes\nProbability: notes"
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "\nProbability\n",
    "section": "",
    "text": "Probability\n\nJan 15, 2024\n\nProbability theory helps us deal with modeling with uncertainty.\nSuppose we perform a experiment like tossing a coin which has a fixed set of possible outcomes. This set is called the \\(\\textbf{sample sapce}\\) and we denote this space with \\(\\Omega\\).\nWe would like to define probabilities for some \\(\\textbf{events}\\), which are subsets of \\(\\Omega\\). The set of events is denoted \\(\\mathcal{F}\\). The \\(\\textbf{complement}\\) of the event \\(\\mathcal{A}\\) is another event, \\(\\mathcal{A}^{c} = \\Omega \\setminus \\mathcal{A}\\)\nThen we can define a \\(\\textbf{probability measure} \\:\\: \\mathbb{P}: \\mathcal{F} \\rightarrow [0, 1]\\) which must satisfy\n\n\\(\\mathbb{P}(\\Omega) = 1\\)\n\\(\\textbf{Countable addivity:}\\) for any countable collection of disjoint sets \\(\\{\\mathcal{A}_i\\} \\subseteq \\mathcal{F}\\),\n\n\\[\n    \\mathbb{P}\\left(\\bigcup_i \\mathcal{A}_i\\right) = \\sum_i \\mathbb{P}(\\mathcal{A}_i)\n\\]\nThe triple \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) is called a \\(\\textbf{probability space}\\).\nIf \\(\\mathbb{P}(\\mathcal{A}) = 1\\), we say that \\(\\mathcal{A}\\) occurs \\(\\textbf{almost surely}\\), and conversely \\(\\mathcal{A}\\) occurs \\(\\textbf{almost never}\\) if \\(\\mathbb{P}(\\mathcal{A}) = 0.\\)\n\\(\\textbf{Proposition}\\): Let \\(\\mathcal{A}\\) be an event. Then\n\n\\(\\mathbb{P}(\\mathcal{A^c}) = 1 - \\mathbb{P}(\\mathcal{A})\\)\nIf \\(\\mathcal{B}\\) is an event and \\(\\mathcal{B} \\subseteq \\mathcal{A}\\), then \\(\\mathbb{P}(\\mathcal{B}) \\leq \\mathbb{P}(\\mathcal{A})\\).\n\\(0 = \\mathbb{P}(\\varnothing) \\leq \\mathbb{P}(\\mathcal{A}) \\leq \\mathbb{P}(\\Omega) = 1\\)\n\n\\(Proof\\):\nUsing the countable additivity of \\(\\mathbb{P}\\), we have\n\\[\n    \\mathbb{P}(\\mathcal{A}) + \\mathbb{P}(\\mathcal{A^c}) = \\mathbb{P}(\\mathcal{A} \\cup \\mathcal{A}^c) = \\mathbb{P}(\\Omega) = 1\n\\]\nTo show 2. suppose \\(\\mathcal{B} \\in \\mathcal{F}\\) and \\(\\mathcal{B} \\subseteq \\mathcal{A}\\). Then\n\\[\n    \\mathbb{P}(\\mathcal{A}) = \\mathbb{P}(\\mathcal{B} \\cup (\\mathcal{A} \\setminus \\mathcal{B})) = \\mathbb{P}(\\mathcal{B}) + \\mathbb{P}(\\mathcal{A} \\setminus \\mathcal{B}) \\geq \\mathbb{P}(\\mathcal{B})\n\\]\nas claimed.\nDiscrete random variables\n\nA random variable denoted as \\(\\text{r.v}\\) is a quantity that probabilistically takes on any of a possible range of values.\nA random variable \\(X\\) is descrete if it takes values in a countable set \\(\\mathcal{X} = \\{x_1, x_2, \\cdots,\\}.\\)\nMost random varibales have some certain distributioin for example Bernoulli, Binomial, Poisson, Geometric."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\nIntroduction\n",
    "section": "",
    "text": "Introduction\n\n\nShortest Path\nFinding the shortest path in this graph:\n\nBased on actions taken by the agent"
  },
  {
    "objectID": "probStats/statRev.html",
    "href": "probStats/statRev.html",
    "title": "\nStatistics and Probability review\n",
    "section": "",
    "text": "Statistics and Probability review\n\n\nRandom variables\n\n\n\n\n\n\n\nDiscrete (Probability Mass Function, p.m.f)\nContinuous (Probability Density Function, p.d.f)\n\n\n\n\n\\(p(x) = \\mathbb{P}(X = x)\\)\n\\(f(x)\\)\n\n\n\\(\\forall x \\quad 0 \\leq p(x) \\leq 1\\)\n\\(\\forall x \\quad f(x) \\geq 0\\)\n\n\n\\(\\sum_{\\text{all } x} p(x) = 1\\)\n\\(\\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\\)\n\n\n\nCumulative distributioin function\n\\(\\text{c.d.f }\\)\n\\(F(x) = \\mathbb{P}(X \\leq x)\\)\n\n\n\n\n\n\n\nDiscrete (c.d.f)\nContinuous (c.d.f)\n\n\n\n\n\\(F(x) = \\sum_{y \\leq x} p(y)\\)\n\\(F(x) = \\int_{-\\infty}^{x} f(y) \\, dy\\)\n\n\n\nExpected value\n\\(\\mathbb{E}(X) = \\mathbf{\\mu}_X\\)\n\n\n\n\n\n\n\nDiscrete Expected value\nContinuous Expected value\n\n\n\n\n\\(\\text{If }\\underset{\\text{all } x} \\sum | x | \\cdot p(x) &lt; \\infty\\)\n\\(\\int_{-\\infty}^{\\infty} | x | \\cdot f(x)dx &lt; \\infty\\)\n\n\n\\(\\mathbb{E}(X) = \\underset{\\text{all } x} \\sum x \\cdot p(x)\\)\n\\(\\mathbb{E}(X) = \\int_{-\\infty}^{\\infty} x\\cdot f(x)dx\\)\n\n\n\\(\\text{If }\\underset{\\text{all } x} \\sum | g(x) | \\cdot p(x) &lt; \\infty\\)\n\\(\\int_{-\\infty}^{\\infty} | g(x) | \\cdot f(x)dx &lt; \\infty\\)\n\n\n\\(\\mathbb{E}(g(X)) = \\underset{\\text{all } x} \\sum g(x) \\cdot p(x)\\)\n\\(\\mathbb{E}(g(X)) = \\int_{-\\infty}^{\\infty} g(x) \\cdot f(x)dx\\)\n\n\n\nVariance\n\\(\\text{Var}(X) = \\sigma^2_X = \\mathbb{E}(\\left[ X - \\mu_{X} \\right]^2) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2\\)\n\n\n\n\n\n\n\nDiscrete Variance\nContinuous Variance\n\n\n\n\n\\(\\text{Var}(X) = \\underset{\\text{all } x} \\sum (x - \\mu_X)^2 \\cdot p(x)\\)\n\\(\\text{Var}(X) = \\int_{-\\infty}^{\\infty} (x - \\mu_X)^2 \\cdot f(x)dx\\)\n\n\n\\(= \\underset{\\text{all } x} \\sum x^2 \\cdot p(x) - \\left[\\mathbb{E}(X)\\right]^2\\)\n\\(= \\left[\\int_{-\\infty}^{\\infty} x^2 \\cdot f(x)dx\\right] - \\left[\\mathbb{E}(X)\\right]^2\\)\n\n\n\nMoment-generating function\n\\(M_X(t) = \\mathbb{E}(\\mathcal{e}^{tX})\\)\n\n\n\n\n\n\n\nDiscrete moment-generating function\nContinuous moment-generating function\n\n\n\n\n\\(M_X(t) = \\underset{\\text{all } x} \\sum \\mathcal{e}^{tx} \\cdot p(x)\\)\n\\(M_X(t) = \\int_{-\\infty}^{\\infty}  \\mathcal{e}^{tx} \\cdot f(x)dx\\)\n\n\n\nExample 1\n\n\n\n\\(x\\)\n\\(p(x)\\)\n\\(F(x)\\)\n\n\n\n\n\\(1\\)\n\\(0.2\\)\n\\(0.2\\)\n\n\n\\(2\\)\n\\(0.4\\)\n\\(0.6\\)\n\n\n\\(3\\)\n\\(0.3\\)\n\\(0.9\\)\n\n\n\\(4\\)\n\\(0.1\\)\n\\(1.0\\)\n\n\n\n\\[\n    F(x) = \\begin{cases}\n            0 & x &lt; 1 \\\\\n            0.2 & 1 \\leq x &lt; 2 \\\\\n            0.6 & 2 \\leq x &lt; 3 \\\\\n            0.9 & 3 \\leq x &lt; 4 \\\\\n            1 & x \\geq 4\n    \\end{cases}\n\\]\n\n\nCode\nlibrary(ggplot2)\n\n# Data\nx &lt;- c(1, 2, 3, 4)\nFx &lt;- c(0.2, 0.6, 0.9, 1.0)\n\n# Creating a data frame\ndata_cdf &lt;- data.frame(x, Fx)\n\n# CDF Plot\nggplot(data_cdf, aes(x = x, y = Fx)) +\n  geom_step(direction = \"hv\", linewidth=1) +  # Creates the step plot\n  geom_point(color=\"red\") +  # Optional: adds points at steps\n  ggtitle(\"Cumulative Distribution Function (CDF)\") +\n  xlab(\"x\") + ylab(\"F(x)\") +\n  theme_minimal()  # Optional: a cleaner theme for the plot"
  },
  {
    "objectID": "probStats/stat410.html",
    "href": "probStats/stat410.html",
    "title": "\nStatistics and Probability 2\n",
    "section": "",
    "text": "Statistics and Probability 2\n\nJan 16, 2024\n\n\nStats and Probability review\nDiscrete Random Variables 1\nDiscrete Random Variables 2\nReview Exam 1"
  },
  {
    "objectID": "cs421/cs421.html",
    "href": "cs421/cs421.html",
    "title": "\nCS 421\n",
    "section": "",
    "text": "CS 421\n\n\n\nBasic OCaml Programming"
  },
  {
    "objectID": "CS374/lab7b.html",
    "href": "CS374/lab7b.html",
    "title": "\nDymamic programming\n",
    "section": "",
    "text": "Dymamic programming\nNov 22, 2023\nHow long is the longest increasing subsequence?\n4 1 2 7 6 5 8 9 3   1 2 6 8 9\nLets define a couple defintions to fromulate this:"
  },
  {
    "objectID": "CS374/lab7b.html#visulization-of-sequence",
    "href": "CS374/lab7b.html#visulization-of-sequence",
    "title": "\nDymamic programming\n",
    "section": "Visulization of sequence",
    "text": "Visulization of sequence\n\n\nCode\nlibrary(ggplot2)\n\n# Your original sequence\nsequence &lt;- c(4, 1, 2, 7, 6, 5, 8, 9, 3)\n\n# The known LIS\nlis &lt;- c(1, 2, 7, 8, 9)\n\n# Create a data frame for the original sequence\ndata &lt;- data.frame(x = 1:length(sequence), y = sequence)\n\n# Identify the indices of the LIS in the original sequence\nlis_indices &lt;- match(lis, sequence)\n\n# Create a data frame for the LIS\nlis_data &lt;- data.frame(x = lis_indices, y = lis)\n\n# Plotting the sequence and the LIS\nggplot(data, aes(x, y)) + \n  geom_point() + \n  geom_line(color = \"gray\") +\n  geom_point(data = lis_data, aes(x, y), color = \"red\") +\n  geom_line(data = lis_data, aes(x, y), color = \"red\") +\n  scale_x_continuous(breaks = 1:length(sequence)) +  \n  scale_y_continuous(breaks = 1:max(sequence)) +  \n  labs(x = \"Index\", y = \"Value\", title = \"Sequence with Highlighted LIS 1 2 7 8 9\")\n\n\n\n\n\n\n\n\nFigure¬†1: Plot of the sequence with the highlighted LIS 1 2 7 8 9\n\n\n\n\n\nThere could be multiple subsequences but we only care about the maximum increasing subsequence.\n\nHere is my animated plot:\n\n\n\nAnimated Plot\n\n\n\nDymamic programming\n\n\nDescribe and analyze dynamic programming algorithms for the following longest-subsequence problems.\n\nGiven an array \\(A[1...n]\\) of integers, compute the length of a longest increasing subsequence of \\(A\\)."
  },
  {
    "objectID": "CS374/dataStructures.html",
    "href": "CS374/dataStructures.html",
    "title": "\nData Strcutures\n",
    "section": "",
    "text": "Data Strcutures\n\nDec 31, 2023\n\n\nLinked List: notes\nHash Table: notes\nBinary Tress\nRandom Binary Search Trees\nRed-Black Trees\nHeaps\nSorting algorithms: notes\nGraph: notes\nExternal Memory Searching"
  },
  {
    "objectID": "CS374/lab1a.html",
    "href": "CS374/lab1a.html",
    "title": "\nString Induction\n",
    "section": "",
    "text": "String Induction\n\nNov 22, 2023"
  },
  {
    "objectID": "CS374/lab8a.html",
    "href": "CS374/lab8a.html",
    "title": "\nEdit distance\n",
    "section": "",
    "text": "Edit distance\n\n\n\nThe minimum number of character insertions, deletions, and substitutions needed to convert one string into another is known as the edit distance between those two strings.\nGiven two strings word1 and word2, return the minimum number of operations required to convert word1 to word2.\nYou have the following three operations permitted on a word:\n\nInsert a character\nDelete a character\nReplace a character"
  },
  {
    "objectID": "RL/mathematics.html",
    "href": "RL/mathematics.html",
    "title": "\nMathematics\n",
    "section": "",
    "text": "Mathematics\n\nJan 15, 2024\n\n\nLinear Algebra: notes\nProbability: notes"
  },
  {
    "objectID": "RL/gymnasium.html",
    "href": "RL/gymnasium.html",
    "title": "\nGymnasium\n",
    "section": "",
    "text": "Gymnasium\n\nJan 12, 2024\n\n\nEnv"
  },
  {
    "objectID": "RL/linearAlgebra.html",
    "href": "RL/linearAlgebra.html",
    "title": "\nLinear Algebra\n",
    "section": "",
    "text": "Linear Algebra\n\nJan 15, 2024\n\n Vector spaces\nA vector space \\(V\\) is a set, the elements of which are called \\(\\textbf{vectors}\\), on which two operations are defined: vectors can be added together, and vectors can be multiploed by real numbers (\\(\\textbf{scalars}\\)).\nWith this \\(V\\) must statisfy the following:\n\nThere exists an additive identity \\(\\mathbf{0}\\) in \\(V\\) such that \\(\\mathbf{x} + \\mathbf{0} = \\mathbf{x}\\) for all \\(\\mathbf{x} \\in V\\)\nFor each \\(\\mathbf{x} \\in V\\), there exists and additive inverse, \\(-\\mathbf{x}\\), such that \\(\\mathbf{x} + (-\\mathbf{x}) = \\mathbf{0}\\)\nThere exists a multiplicative identity (written 1) in \\(\\mathbb{R}\\) such that \\(1\\mathbf{x} = \\mathbf{x}\\) for all \\(\\mathbf{x} \\in V\\)\nCommutativity: \\(\\mathbf{x} + \\mathbf{y} = \\mathbf{y} + \\mathbf{x}\\) for all \\(\\mathbf{x}, \\mathbf{y} \\in V\\)\nAssociativity: \\((\\mathbf{x} + \\mathbf{y}) + \\mathbf{z} = \\mathbf{x} + (\\mathbf{y} + \\mathbf{z})\\) and \\(\\alpha(\\beta \\mathbf{x}) = (\\alpha\\beta)\\mathbf{x}\\) for all \\(\\mathbf{x}, \\mathbf{y}, \\mathbf{z} \\in V\\) and \\(\\alpha, \\beta \\in \\mathbb{R}\\)\nDistributivity: \\(\\alpha(\\mathbf{x} + \\mathbf{y}) = \\alpha\\mathbf{x} + \\alpha\\mathbf{y}\\) and \\((\\alpha + \\beta)\\mathbf{x} = \\alpha\\mathbf{x} + \\beta\\mathbf{x}\\) for all \\(\\mathbf{x}, \\mathbf{y} \\in V\\) and \\(\\alpha, \\beta \\in \\mathbb{R}\\)\n\nA set of vectors \\(\\mathbf{v}_1, \\cdots, \\mathbf{v}_n \\in V\\) is said to be \\(\\textbf{linearly independent}\\) if\n\\[\n    \\alpha \\mathbf{v}_n + \\cdots + \\alpha_n\\mathbf{v}_n = \\mathbf{0} \\quad \\text{ imlpies } \\quad\\alpha_1 = \\cdots = \\alpha_n = 0.\n\\]\nThe \\(\\textbf{span}\\) of \\(\\mathbf{v}_1, \\cdots, \\mathbf{v}_n \\in V\\) is the set of all vectors that can be expressed of a linear combination of them:\n\\[\n    \\text{span}\\{\\mathbf{v}_1, \\cdots, \\mathbf{v}_n\\} = \\{\\mathbf{v} \\in V : \\exists\\alpha, \\cdots, \\alpha_n \\text{ such that } \\alpha\\mathbf{v}_1 + \\cdots + \\alpha_n\\mathbf{v}_n = \\mathbf{v}\\}\n\\]\nIf the set of vectors is linearly independent and its span is the whole \\(V\\), those vectors are said to be a \\(\\textbf{basis}\\) for \\(V\\). In fact, every linear independent set of vectors forms a basis for its span.\nIf a vector space is spanned by a finite numbers of vectors, it is said to be \\(\\textbf{finite-dimensional}\\). Otherwise it is \\(\\textbf{infinite-dimensional}\\). The number of vectors in a basis for a finite-dimensional vector space \\(V\\) is called the \\(\\textbf{dimension}\\) of \\(V\\) and demoted dim \\(V\\).\n Euclidean space\nThe quintessential vector space is \\(\\textbf{Eculidean space}\\), which we denote \\(\\mathbb{R}^n\\). The vectors in this space consist of \\(n\\)-tuples of real numbers:\n\\[\n    \\mathbf{x} = \\left(x_1, x_2, \\cdots, x_n\\right)\n\\]\nIt is also useful to consider them as a \\(n \\times 1\\) matrices, or \\(\\textbf{column vectors}\\):\n\\[\n    \\mathbf{x} = \\begin{bmatrix}\n        x_{1} \\\\\n        x_{1} \\\\\n        \\vdots \\\\\n        x_{n}\n        \\end{bmatrix}\n\\]\nAddition and scalar multiplication are defined component-wise on vectors in \\(\\mathbb{R}^n\\). \\[\n    \\mathbf{x} + \\mathbf{y} = \\begin{bmatrix}\n        x_{1} + y{1} \\\\\n        x_{1} + y_{2}\\\\\n        \\vdots \\\\\n        x_{n} + y_{n}\n        \\end{bmatrix}, \\qquad \\alpha\\mathcal{x} = \\begin{bmatrix}\n                                                    \\alpha x_{1} \\\\\n                                                    \\vdots \\\\\n                                                    \\alpha x_{n}\n                                                    \\end{bmatrix}\n\\]\nEuclidean space is used to mathematically represent physical space, with notions such as distance, length, and angles. Although it becomes hard to visualize fot \\(n &gt; 3\\), these concepts generalize mathematically in obvious ways. Even when you‚Äôre wokring in more general settings than \\(\\mathbb{R}^n\\), it is often useful to visualize vector addition and scalalr multiplication in terms of \\(2D\\) vectors in the plane or \\(3D\\) vectors in space.\nSubspaces\nVector spaces can contain other vector spaces. If \\(V\\) is a vector space, then \\(\\mathcal{S} \\subseteq V\\) is said to be a \\(\\textbf{subspace}\\) of \\(V\\) if:\n\n\\(\\mathbf{0} \\in \\mathcal{S}\\)\n\\(\\mathcal{S}\\) is closed under addition: \\(\\mathbf{x}, \\mathbf{y} \\in \\mathcal{S}\\) implies \\(\\mathbf{x} + \\mathbf{y} \\in \\mathcal{S}\\)\n\\(\\mathcal{S}\\) is closed under scalar multiplication: \\(\\mathbf{x} \\in \\mathcal{S}, \\alpha \\in \\mathbb{R}\\) implies \\(\\alpha\\mathbf{x} \\in \\mathcal{S}\\)\n\nNote that \\(V\\) is always a subsapce of \\(V\\), as is the trivial vector space which contains only \\(\\mathbf{0}\\). As a concrete example, a line passing through the origin is a subsapce of Eculidean space. If \\(U\\) and \\(W\\) are subspaces of \\(V\\), then their sum is defined as\n\\[\n    U + W = \\{\\mathbf{u} + \\mathbf{w} \\mid \\mathbf{u} \\in U, \\mathbf{w} \\in W \\}\n\\]\nIf \\(U \\cap W = \\{\\mathbf{0}\\}\\), the sum is said to be a \\(\\textbf{direct sum}\\) and written \\(U \\oplus W\\). Every vector in \\(U \\oplus W\\) can be written uniquely as \\(\\mathbf{u} + \\mathbf{w}\\) for some \\(\\mathbf{u} \\in U\\) and \\(\\mathbf{w} \\in W\\).\nThe dimensions of sums of subspaces obey a friendly relationship:\n\\[\n    \\text{dim}(U + W) = \\text{dim } U + \\text{dim } W - \\text{dim}(U \\cap W)  \n\\]\nIt follows that\n\\[\n    \\text{dim}(U \\oplus W) = \\text{dim } U + \\text{dim } W\n\\]\nsince \\(\\text{dim}(U \\cap W) = \\text{dim}(\\{\\mathbf{0}\\}) = 0\\) if the sum is direct.\nLinear maps\nA \\(\\textbf{linear map}\\) is a function \\(T: V \\rightarrow W\\), where \\(V\\) and \\(W\\) are vector spaces, that statisfies\n\n\\(T(\\mathbf{x} + \\mathbf{y}) = T\\mathbf{x} + T\\mathbf{y} \\text{ for all } \\mathbf{x}, \\mathbf{y} \\in V\\)\n\\(T(\\alpha\\mathbf{x}) = \\alpha T\\mathbf{x} \\text{ for all } \\mathbf{x} \\in V, \\alpha \\in \\mathbb{R}\\)\n\nA linear map from \\(V\\) to itself is called a \\(\\textbf{linear operator}\\).\n Matrices and transposes\n\n\\(A\\) is a \\(m \\times n\\) real matrix, wrtitten \\(A \\in \\mathbb{R}^{m \\times n}\\), if: \\[\nA = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\n\nwhere \\(a_{i, j} \\in \\mathbb{R}\\). The \\((i, j)\\)th entry of \\(A\\) is \\(A_{i, j} = a_{i, j}\\).\n\nThe transpose of \\(A \\in \\mathbb{R}\\) is define as: \\[\nA^{T} = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\n\nsuch that, \\((A^{T})_{i, j} = A_{j, i}\\)\nNote: \\(x \\in \\mathbb{R}^{n}\\) is considered to be a columnn vector in \\(\\mathbb{R}^{n \\times 1}\\)\nSums and products of matrcies \n\nThe sum of matrices \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(B \\in \\mathbb{R}^{m \\times n}\\) is the matrix \\(A + B \\in \\mathbb{R}^{m \\times n}\\) such that \\[\n  (A + B)_{i, j} = A_{i, j} + B_{i, j}\n\\]\nThe product of matrices \\(A \\in \\mathbb{R}^{m \\times n}\\) and \\(B \\in \\mathbb{R}^{n \\times \\ell}\\) is the matrix \\(AB \\in \\mathbb{R}^{m \\times \\ell}\\) such that\n\n\\[\n    (AB)_{i, j} = \\sum_{k=1}^n   A_{i, k} B_{k, j}\n\\]"
  },
  {
    "objectID": "RL/intro.html",
    "href": "RL/intro.html",
    "title": "\nIntroduction\n",
    "section": "",
    "text": "Introduction\n\n\nIntroduction to MDPs and RL\nShortest Path\nFinding the shortest path:\nWhere we have a graph \\(G = (V, E)\\) where \\(V\\) are the vertices and \\(E\\) are the edges with weights \\(w\\). The vertices are the \\(\\textbf{states}\\) and the edges are the \\(\\textbf{actions}\\). Tne goal is you have a starting state and you wanna reach the end state while attating the least cost of the wieghts \\(w\\) along the edges. If the startegy is \\(\\textbf{Greedy}\\) then it is suboptimal due to dealyed affects of long term decisions. There must be a better way to long-term planning.\n\nBased on actions taken by the agent"
  },
  {
    "objectID": "CS421/cs421.html",
    "href": "CS421/cs421.html",
    "title": "\nCS 421\n",
    "section": "",
    "text": "CS 421\n\n\n\nIntroduction to Objective OCaml\nPolymoprhic Typing Rules\nBasic OCaml Programming\nClosures and Evaluation of Function Application, Order of Evaluation in OCaml\nHigher-Order Functions, Pattern Matching and Recursion over Lists\nUser Defined Types in Ocaml, Data Constructors and Pattern Matching\nTypes and Type Systems\nMidterm 2 concepts review"
  },
  {
    "objectID": "CS411/cs411.html",
    "href": "CS411/cs411.html",
    "title": "\nCS 411\n",
    "section": "",
    "text": "CS 411\n\n\n\nThe Relational Model & Basic SQL\nHigh-Level Database Models"
  },
  {
    "objectID": "RL/mdp.html",
    "href": "RL/mdp.html",
    "title": "\nMarkov decision process\n",
    "section": "",
    "text": "Markov decision process\n\\[\n\\def\\emph#1{\\textit{#1}}\n\\]\nIn reinforcement learning, the interactions between the agent and the environment are often described by a state space \\(\\mathcal{S}\\), action space \\(\\mathcal{A}\\), transition function \\(P : \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\Delta(\\mathcal{S})\\); where \\(\\Delta(\\mathcal{S})\\) is the space of probability distributions over \\(\\mathcal{S}\\) (i.e., the probability simplex). \\(P(s^\\prime \\mid s, a)\\) is the probability of transitioning into state \\(s^\\prime\\) upton taking action \\(a\\) in state \\(s\\). A reward function \\(R : \\mathcal{S} \\times \\mathcal{A} \\rightarrow [0, R_{max}]\\). where \\(R_{max} &gt; 0\\) is a constant. \\(R(s, a)\\) is the immediate reward associated with taking action \\(a\\) in state \\(s\\). A discount factor \\(\\gamma \\in [0, 1)\\) , which defines the horizon for the problem."
  },
  {
    "objectID": "RL/mdp.html#opengym",
    "href": "RL/mdp.html#opengym",
    "title": "\nMarkov decision process\n",
    "section": "OpenGym",
    "text": "OpenGym\n\nInitialize the Environment\nimport gym \nenv = gym.make('MountainCar-v0')\n\n\nMountain car\nIn the Mountain Car Markov Decision Process (MDP), a car is randomly positioned at the lowest point of a sinusoidally-shaped valley. This MDP operates deterministically, providing a set of possible accelerative actions that can be executed to move the car either forward or backward. The objective is to judiciously use these accelerations to navigate the car to the target location, situated at the peak of the hill to the right. Within the gym framework, the mountain car scenario comes in two variants: one allowing for a discrete set of actions, and the other permitting a continuum of actions. The variant in question here is the one that employs discrete actions.\nclass MountainCarEnv(gym.Env):\n    def __init__(self, render_mode: Optional[str] = None, goal_velocity=0):\n        self.min_position = -1.2\n        self.max_position = 0.6\n        self.max_speed = 0.07\n        self.goal_position = 0.5\n        self.goal_velocity = goal_velocity\n\n        self.force = 0.001\n        self.gravity = 0.0025\n\n        self.low = np.array([self.min_position, -self.max_speed], dtype=np.float32)\n        self.high = np.array([self.max_position, self.max_speed], dtype=np.float32)\n\n        self.render_mode = render_mode\n\n        self.screen_width = 600\n        self.screen_height = 400\n        self.screen = None\n        self.clock = None\n        self.isopen = True\n\n        self.action_space = spaces.Discrete(3)\n        self.observation_space = spaces.Box(self.low, self.high, dtype=np.float32)"
  },
  {
    "objectID": "RL/probability.html",
    "href": "RL/probability.html",
    "title": "\nProbability\n",
    "section": "",
    "text": "Probability\n\nJan 15, 2024\n\nProbability theory helps us deal with modeling with uncertainty.\nSuppose we perform a experiment like tossing a coin which has a fixed set of possible outcomes. This set is called the \\(\\textbf{sample sapce}\\) and we denote this space with \\(\\Omega\\).\nWe would like to define probabilities for some \\(\\textbf{events}\\), which are subsets of \\(\\Omega\\). The set of events is denoted \\(\\mathcal{F}\\). The \\(\\textbf{complement}\\) of the event \\(A\\) is another event, \\(A^{c} = \\Omega \\setminus A\\)\nThen we can define a \\(\\textbf{probability measure} \\:\\: \\mathbb{P}: \\mathcal{F} \\rightarrow [0, 1]\\) which must satisfy\n\n\\(\\mathbb{P}(\\Omega) = 1\\)\n\\(\\textbf{Countable addivity:}\\) for any countable collection of disjoint sets \\(\\{\\mathcal{A}_i\\} \\subseteq \\mathcal{F}\\),\n\n\\[\n    \\mathbb{P}\\left(\\bigcup_i A_i\\right) = \\sum_i \\mathbb{P}(A_i)\n\\]\nThe triple \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) is called a \\(\\textbf{probability space}\\).\nIf \\(\\mathbb{P}(A) = 1\\), we say that \\(A\\) occurs \\(\\textbf{almost surely}\\), and conversely \\(A\\) occurs \\(\\textbf{almost never}\\) if \\(\\mathbb{P}(A) = 0.\\)\n\\(\\textbf{Proposition}\\): Let \\(A\\) be an event. Then\n\n\\(\\mathbb{P}(A^c) = 1 - \\mathbb{P}(A)\\)\nIf \\(B\\) is an event and \\(B \\subseteq A\\), then \\(\\mathbb{P}(B) \\leq \\mathbb{P}(A)\\).\n\\(0 = \\mathbb{P}(\\varnothing) \\leq \\mathbb{P}(A) \\leq \\mathbb{P}(\\Omega) = 1\\)\n\n\\(Proof\\):\nUsing the countable additivity of \\(\\mathbb{P}\\), we have\n\\[\n    \\mathbb{P}(A) + \\mathbb{P}(A^c) = \\mathbb{P}(A \\cup A^c) = \\mathbb{P}(\\Omega) = 1\n\\]\nTo show 2. suppose \\(B \\in \\mathcal{F}\\) and \\(B \\subseteq A\\). Then\n\\[\n    \\mathbb{P}(A) = \\mathbb{P}(B \\cup (A \\setminus B)) = \\mathbb{P}(B) + \\mathbb{P}(A \\setminus B) \\geq \\mathbb{P}(B)\n\\]\nas claimed.\nFor 3: the middle inequality follows from 2 since \\(\\varnothing \\subseteq A \\subseteq \\Omega\\). We also have:\n\\[\n    \\mathbb{P}(\\varnothing) = \\mathbb{P}(\\varnothing \\cup \\varnothing) = \\mathbb{P}(\\varnothing) + \\mathbb{P}(\\varnothing)\n\\]\nDiscrete random variables\n\nA random variable denoted as \\(\\text{r.v}\\) is a quantity that probabilistically takes on any of a possible range of values.\nA random variable \\(X\\) is descrete if it takes values in a countable set \\(\\mathcal{X} = \\{x_1, x_2, \\cdots,\\}.\\)\nMost random varibales have some certain distributioin for example Bernoulli, Binomial, Poisson, Geometric."
  },
  {
    "objectID": "CS421/rules.html",
    "href": "CS421/rules.html",
    "title": "\nPolymoprhic Typing Rule\n",
    "section": "",
    "text": "Polymoprhic Typing Rule\n\n\nWe will say a monomorphic type \\(\\tau\\) is an \\(\\textbf{instance}\\) of a polymorphic type \\(\\sigma\\) if there exists a monomorphic type \\(\\tau^\\prime\\), (a possibly empty) list of type variables \\(\\alpha_1, \\cdots, \\alpha_n\\), and a corresponding list of monomorphic types \\(\\tau_1, \\cdots, \\tau_n\\) such that \\(\\sigma = \\forall \\alpha_1, \\cdots, \\alpha_n\\). \\(\\tau^\\prime\\) and \\(\\tau = \\tau^\\prime\\left[\\tau_1 / \\alpha_1, \\cdots, \\tau_n / \\alpha_n\\right]\\), the type gotten by replacing each occurence of \\(\\alpha_i\\) in \\(\\tau^\\prime\\) by \\(\\tau_i\\). When using the rule below that require one type to be an instance of another, you should give the instantiation: \\(\\left[\\tau_1 / \\alpha_1, \\cdots, \\tau_n / \\alpha_n\\right]\\).\nIn simpler terms, think of a polymorphic type like a template and a monomorphic type like a filled-out form of that template. The process described is like saying, ‚ÄúTo prove that this filled-out form is based on a specific template, show me how you substituted the placeholders in the template with actual information to get this form.\n\nSignatures\nPolymorphic constant signatures:\n\n\n\n\n\n\n\n\\(\\text{sig(true) = bool}\\)\n\\(\\text{sig(true) = bool}\\)\n\n\n\n\n\\(\\text{sig}(n) = \\text{int } n \\text{ an integer constant}\\)\n\\(\\text{sig}(f) = \\text{float } f \\text{ a floating point (real) constant}\\)\n\n\n\\(\\text{sig}(s) = \\text{string } s \\text{ a string constant}\\)\n\\(\\text{sig}([ \\:\\: ]) = \\forall \\alpha.\\alpha\\text{list}\\)\n\n\n\nPolymorphic Unary Primitive Operators:\n\n\n\n\n\n\n\n\\(\\text{sig(fst)} = \\forall\\alpha\\beta.(\\alpha * \\beta) \\rightarrow \\alpha\\)\n\\(\\text{sig(snd)} = \\forall\\alpha\\beta.(\\alpha * \\beta) \\rightarrow \\beta\\)\n\n\n\n\n\\(\\text{sig(hd)} = \\forall\\alpha.\\alpha\\text{list} \\rightarrow \\alpha\\)\n\\(\\text{sig(tl)} = \\forall\\alpha.\\alpha\\text{list} \\rightarrow \\alpha \\text{ list}\\)\n\n\n\\(\\text{sig}(\\sim) = \\text{int } \\rightarrow \\text{ int}\\)\n\\(\\text{sig(print\\_string)} = \\text{string } \\rightarrow \\text{ unit}\\)\n\n\n\\(\\text{sig(not)} = \\text{bool } \\rightarrow \\text{ bool}\\)\n\n\n\n\nPolymorphic Binary Primitive Operators:\n\n\n\n\n\n\n\n\\(\\text{sig}(\\oplus) = \\text{int} \\rightarrow \\text{ int} \\rightarrow \\text{ int for } \\oplus \\in \\{+, -, *, \\text{mod}, /\\}\\)\n\\(\\text{sig}( ^\\wedge ) = \\text{string } \\rightarrow \\text{ stirng} \\rightarrow \\text{ string}\\)\n\n\n\n\n\\(\\text{sig}(\\oplus) = \\text{float} \\rightarrow \\text{ float} \\rightarrow \\text{ float for } \\oplus \\in \\{+., -., *., /., **\\}\\)\n\\(\\text{sig}((\\_, \\_)) = \\forall\\alpha\\beta.\\alpha \\rightarrow \\beta \\rightarrow \\alpha * \\beta\\)\n\n\n\\(\\text{sig}(\\wr) = \\text{bool} \\rightarrow \\text{ bool} \\rightarrow \\text{ bool for } \\wr \\in \\{\\vert \\vert, \\&\\&\\}\\)\n\\(\\text{sig}(::) = \\forall\\alpha.\\alpha \\rightarrow \\alpha \\text{ list} \\rightarrow \\alpha \\text{ list}\\)\n\n\n\\(\\text{sig}(\\approx) = \\forall\\alpha.\\alpha \\rightarrow \\alpha \\rightarrow \\text{bool for } \\approx  \\:\\: \\in \\{&lt;, &gt;, =, &lt;=, &gt;=, &lt;&gt;\\}\\)\n\n\n\n\n\n\nRules\nConstants:\n\\(\\large{\\frac{}{\\Gamma \\:\\: \\vdash \\: c \\: : \\: \\tau }}\\) \\(\\text{\\large{CONST} } \\text{where }  c \\text{ is a constant listed above, and } \\tau \\text{ is an instance of sig}(c)\\)\nVariables:\n\\(\\large{\\frac{}{\\Gamma \\:\\: \\vdash \\: x \\: : \\: \\tau }}\\) \\(\\text{\\large{VAR}}\\) \\(\\text{ where } x \\text{ is a variable and } \\tau \\text{ is an instance of } \\Gamma(x)\\)\nUnary Primitive Operators:\n\\(\\large\\frac{\\Gamma \\:\\: \\vdash \\: e \\: : \\: \\tau_1}{\\Gamma \\:\\: \\vdash \\: \\oplus e \\: : \\: \\tau_2}\\) \\(\\text{\\large{MONOP}}\\) \\(\\quad\\tau_1 \\rightarrow \\tau_2 \\text{ an instance of sig}(\\oplus)\\)\nBinary Prmitive Operators:\n\\(\\large{\\frac{\\Gamma \\:\\: \\vdash \\: e_1 \\: : \\: \\tau_1 \\quad \\Gamma \\:\\: \\vdash e_2 \\: : \\: \\tau_2}{\\Gamma \\:\\: \\vdash \\: e_1 \\: \\odot \\: e_2 \\: : \\: \\tau_3}}\\) \\(\\text{\\large{BINOP}}\\) \\(\\qquad \\tau_1 \\rightarrow \\tau_2 \\rightarrow \\tau_3 \\text{ an instance of sig}(\\odot)\\)\nIf then else rule:\n\\(\\large{\\frac{\\Gamma \\:\\: \\vdash \\: e_c \\: : \\: \\text{bool} \\quad \\Gamma \\:\\: \\vdash \\: e_t \\: : \\: \\tau  \\quad \\Gamma \\:\\: \\vdash e_e \\: : \\: \\tau}{\\Gamma \\:\\: \\vdash \\: \\text{if} \\: e_c \\: \\text{then} \\: e_t \\: \\text{else} \\: e_e \\: : \\: \\tau}}\\) \\(\\text{\\large{IF}}\\)\nApplication rule:\n\\(\\large{\\frac{\\Gamma \\:\\: \\vdash \\: e_1 \\: : \\: \\tau_1 \\:\\rightarrow \\: \\tau_2 \\quad \\Gamma \\:\\: \\vdash e_2 \\: : \\: \\tau_1}{\\Gamma \\:\\: \\vdash \\:  e_1 \\: e_2 \\: : \\: \\tau_2}}\\) \\(\\text{\\large{APP}}\\)"
  },
  {
    "objectID": "CS421/rules.html#signatures",
    "href": "CS421/rules.html#signatures",
    "title": "\nPolymoprhic Typing Rule\n",
    "section": "Signatures",
    "text": "Signatures\nPolymorphic constant signatures:\n\n\n\n\n\n\n\n\\(\\text{sig(true) = bool}\\)\n\\(\\text{sig(true) = bool}\\)\n\n\n\n\n\\(\\text{sig}(n) = \\text{int } n \\text{ an integer constant}\\)\n\\(\\text{sig}(f) = \\text{float } f \\text{ a floating point (real) constant}\\)\n\n\n\\(\\text{sig}(s) = \\text{string } s \\text{ a string constant}\\)\n\\(\\text{sig}([ \\:\\: ]) = \\forall \\alpha.\\alpha\\text{list}\\)\n\n\n\nPolymorphic Unary Primitive Operators:\n\n\n\n\n\n\n\n\\(\\text{sig(fst)} = \\forall\\alpha\\beta.(\\alpha * \\beta) \\rightarrow \\alpha\\)\n\\(\\text{sig(snd)} = \\forall\\alpha\\beta.(\\alpha * \\beta) \\rightarrow \\beta\\)\n\n\n\n\n\\(\\text{sig(hd)} = \\forall\\alpha.\\alpha\\text{list} \\rightarrow \\alpha\\)\n\\(\\text{sig(tl)} = \\forall\\alpha.\\alpha\\text{list} \\rightarrow \\alpha \\text{ list}\\)\n\n\n\\(\\text{sig}(\\sim) = \\text{int } \\rightarrow \\text{ int}\\)\n\\(\\text{sig(print\\_string)} = \\text{string } \\rightarrow \\text{ unit}\\)\n\n\n\\(\\text{sig(not)} = \\text{bool } \\rightarrow \\text{ bool}\\)\n\n\n\n\nPolymorphic Binary Primitive Operators:\n\n\n\n\n\n\n\n\\(\\text{sig}(\\oplus) = \\text{int} \\rightarrow \\text{ int} \\rightarrow \\text{ int for } \\oplus \\in \\{+, -, *, \\text{mod}, /\\}\\)\n\\(\\text{sig}( ^\\wedge ) = \\text{string } \\rightarrow \\text{ stirng} \\rightarrow \\text{ string}\\)\n\n\n\n\n\\(\\text{sig}(\\oplus) = \\text{float} \\rightarrow \\text{ float} \\rightarrow \\text{ float for } \\oplus \\in \\{+., -., *., /., **\\}\\)\n\\(\\text{sig}((\\_, \\_)) = \\forall\\alpha\\beta.\\alpha \\rightarrow \\beta \\rightarrow \\alpha * \\beta\\)\n\n\n\\(\\text{sig}(\\wr) = \\text{bool} \\rightarrow \\text{ bool} \\rightarrow \\text{ bool for } \\wr \\in \\{\\vert \\vert, \\&\\&\\}\\)\n\\(\\text{sig}(::) = \\forall\\alpha.\\alpha \\rightarrow \\alpha \\text{ list} \\rightarrow \\alpha \\text{ list}\\)\n\n\n\\(\\text{sig}(\\approx) = \\forall\\alpha.\\alpha \\rightarrow \\alpha \\rightarrow \\text{bool for } \\approx  \\:\\: \\in \\{&lt;, &gt;, =, &lt;=, &gt;=, &lt;&gt;\\}\\)"
  },
  {
    "objectID": "CS421/rules.html#rules",
    "href": "CS421/rules.html#rules",
    "title": "\nPolymoprhic Typing Rule\n",
    "section": "Rules",
    "text": "Rules"
  },
  {
    "objectID": "probStats/discreteVariable.html",
    "href": "probStats/discreteVariable.html",
    "title": "\nDiscrete Random Variables 1\n",
    "section": "",
    "text": "Discrete Random Variables 1\n\nJan 17, 2024\n\nTerminology\nInformally, a \\(\\textbf{random variable}\\) is a quantity \\(X\\) whose value depends on some random event. The \\(\\textbf{space (or range)}\\) of \\(X\\) is the set \\(S\\) of possible values of \\(X\\). If this set \\(S\\) is finite or countable (i.e., can be listed as a sequence \\((x_1. x_2, \\cdots\\)), the random variable is called \\(\\textbf{discrete}\\).\nGeneral formulas\n\n\\(\\textbf{Probability mass function (p.m.f):}\\)\n\n\\(f(x) = \\mathbb{P}(X = x)\\) for all \\(x \\in S\\)\n\\(f(x) \\geq 0\\) and \\(\\underset{x \\in S}{\\sum} f(x) = 1\\)\n\\(\\textbf{Uniform distribution}\\) on a set \\(S\\): Each of the values \\(x \\in S\\) has the same probability, i.e., \\(f(x) = 1/n\\) for each value \\(x\\), where \\(n\\) is the number of values.\n\n\\(\\textbf{Expectation (mean):}\\)\n\n\\(\\mu = \\mathbb{E}(X) = \\underset{x \\in S}{\\sum} x \\cdot f(x)\\)\n\\(\\mathbb{E}(c) = c, \\:\\: \\mathbb{E}(cX) = c\\mathbb{E}(X), \\:\\: \\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y)\\)\n\\(\\textbf{Expectation of a function of } X: \\mathbb{E}(u(X)) = \\underset{x \\in S}{\\sum} u(x)f(x)\\)\n\n\\(\\textbf{Variance:}\\)\n\n\\(\\sigma^2 = \\text{Var}(X) = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2\\)\n\\(\\text{Var}(X) = \\mathbb{E}((X - \\mu)^2)\\)\n\\(\\text{Var}(c) = 0, \\:\\: \\text{Var}(cX) = c^2\\:\\text{Var}(X), \\:\\: \\text{Var}(X + c) = \\text{Var}(X)\\)\n\\(\\textbf{Standard deviation}: \\sigma = \\sqrt{\\text{Var}(X)}\\)\n\n\\(\\textbf{Moment-generating function:}\\)\n\n\\(M(t) = \\mathbb{E}(\\mathcal{e}^{tX}) = \\underset{x \\in S}{\\sum} \\mathcal{e}^{tx} f(x)\\)\nThe derivatives of \\(M(t)\\) at 0 generate the moments of \\(X: M^{\\prime} (0) = \\mathbb{E}(X), M^{\\prime\\prime}(0) = \\mathbb{E}(X^2), \\:\\: M^{\\prime\\prime\\prime} (0) = \\mathbb{E}(X^3),\\) etc."
  },
  {
    "objectID": "probStats/discreteVariable.html#terminology",
    "href": "probStats/discreteVariable.html#terminology",
    "title": "\nDiscrete Random Variables 1\n",
    "section": "Terminology",
    "text": "Terminology"
  },
  {
    "objectID": "probStats/discreteVariable2.html",
    "href": "probStats/discreteVariable2.html",
    "title": "\nDiscrete Random Variables 2\n",
    "section": "",
    "text": "Discrete Random Variables 2\n\nJan 17, 2024\n\nThe Big Three\nThe following is a list of essentail formulaas for the three most important discrete distributions: \\(\\textbf{binomial, geometric, and Poisson.}\\)\n\n\\(\\textbf{Binomial distribution } b(n, p):\\)\n\n\\(n \\text{ (positive integer), } p \\: (0 \\leq p \\leq 1)\\)\n\\(\\textbf{p.m.f: } f(x) = {n \\choose x}p^x (1 - p)^{n - x} \\:\\: (x = 0, 1, 2, ..., n)\\)\n\\(\\textbf{Expectation and variance: } \\mu = np, \\:\\: \\sigma^2 = np(1 - p)\\)\n\\(\\textbf{Arises as: }\\) Distribution of number of successes in success/failure trials (Bernoulli trials)\n\n\\(\\textbf{Geometric distribution:}\\)\n\n\\(p \\: (0 &lt; p &lt; 1)\\)\n\\(\\textbf{p.m.f: } f(x) = (1 - p)^{x - 1} p \\:\\: (x =1, 2, ...)\\)\n\\(\\textbf{Expectation and variance: } \\mu = 1/p, \\: \\sigma^2 = (1 - p)/p^2\\)\n\\(\\textbf{Geometric series: } \\overset{\\infty}{\\underset{n=0}{\\sum}} r^n = \\frac{1}{1 - r} (| r | &lt; 1)\\)\n\\(\\textbf{Arises as: }\\) Distribution of trial at which the first success occurs in success/failure trial sequence\n\n\\(\\textbf{Poisson disctribution:}\\)\n\n\\(\\lambda &gt; 0\\)\n\\(\\textbf{p.m.f: } f(x) = \\mathcal{e}^{-\\lambda \\frac{\\lambda^x}{x!}} \\:\\: (x = 0, 1, 2, ...)\\)\n\\(\\textbf{Expectation and variance: }\\overset{\\infty}{\\underset{n=0}{\\sum}} \\frac{\\lambda^n}{n!} = \\mathcal{e}^\\lambda\\)\n\\(\\textbf{Arises as: }\\) Distribution of number of occurrences of rare events, such as accidents, insurance claims, etc.\n\n\nOther discrete distributions\n\n\\(\\textbf{Hypergeometric distribution:} f(x) = \\frac{ {N_1 \\choose x} {N_2 \\choose n - x} }{N \\choose n}\\), \\(x = 0, 1, ..., N_1, n - x \\leq N_2\\)\n\\(\\textbf{Negative binomial distribution:} f(x) = {x - 1 \\choose r - 1}(1 - p)^{x - r}p^r\\), \\(\\quad x = r, r + 1, ...\\)\n\nBinomial coefficients\n\n\\(\\textbf{Definition: } \\text{For } n = 1, 2, ... \\text{ and } k = 0, 1, ..., n, {n \\choose k} = \\frac{n!}{k!(n - k)!}\\)\n\\(\\textbf{Alternate notations: } {}_n C_k \\text{ or } C(n, k)\\)\n\\(\\text{Other definition:} {n \\choose k} = \\frac{n(n-1)...(n - k + 1)}{k!}\\)\n\\(\\textbf{Symmetry property: } {n \\choose k} = {n \\choose n - k}\\)\n\\(\\textbf{Special cases: } {n \\choose 0} = {n \\choose n} = 1, \\:\\: {n \\choose 1} = {n \\choose n - 1} = n\\)\n\\(\\textbf{Binomial Theorem: } (x + y)^n = \\overset{n}{\\underset{k=0}{\\sum}} {n \\choose k} x^k y^{n - k}\\)\n\\(\\textbf{Binomial Theorem, special case: } (x + y)^n = \\overset{n}{\\underset{k=0}{\\sum}} {n \\choose k} p^k(1 - p)^{n - k} = 1\\)\n\\(\\textbf{Combinatorial Interpretations: } {n \\choose k} \\text{ represents }\\)\n\n\nthe number of ways to select \\(k\\) objects out of \\(n\\) given objects (in the sense of unordered samples wihtout replacement)\nthe number of \\(k\\)-element subsets of an \\(n\\)-element set\nthe number of \\(n\\)-letter \\(\\text{HT}\\) sequences with exactly \\(k\\) \\(\\text{H's}\\) and \\(n - k\\) \\(\\text{T's}\\)\n\n\n\\(\\textbf{Binomial distribution: }\\) Given a positive integer \\(n\\) and a number \\(p\\) with \\(0 &lt; p &lt; 1\\), the binomial distribution \\(b(n, p)\\) is the distribution with density (p.m.f) \\(f(x) = {n \\choose x} p^x(1 - p)^{n - x}\\), for \\(x = 0, 1, ..., n\\)."
  },
  {
    "objectID": "CS411/RDBMS.html",
    "href": "CS411/RDBMS.html",
    "title": "\nThe Relational Model & Basic SQL\n",
    "section": "",
    "text": "The Relational Model & Basic SQL\n\nJan 19, 2024\n\n Data models\nA data model is a notation for describing data or information.\n\nStructure of the data\n\nOperations of the data\nConstraints on the data\n\nThe relational model is based on tables, which I try to formulate in the bottom example. This relation, or table describes a databse for a students in undergrad who are pursuing a computer science majors: each entry as the university of attendends, their name, current year, and major.\n\n\n\nuniversity\nstudent_name\nyear\nmajor\n\n\n\n\nUIUC\nJogre Velez\nsenior\ncomputer science\n\n\n\nA relational database is a big spreadsheet that several people can update simultaneously.\nIn the context of a banking system, a relational database functions like a highly organized and efficient digitial ledger, allowing multiple transactions and operations to be processed simultaneously.\nEach table in this database can be likened to a distinct ledger or register. For instance, consider a table specifically designed to store bank account information. In this table, each column represents a different attribute of a bank account, such as the account number, account holder‚Äôs name, balance, and account type. Every row in the table corresponds to an individual bank account, containing all the relevant details for that account.\nUnlike a traditional spreadsheet, a relational database management system (RDBMS) requires that all data within a single column be of the same data type, like integer, decimal, string, or date. This ensures data integrity and consistency. Another key difference is that rows in an RDBMS are not inherently ordered. While you can create an indexed column, such as account_number, to organize and retrieve data in a specific order, the database itself does not automatically assign a sequential order like spreadsheet applications (e.g., Excel).\nTo illustrate, here‚Äôs an example of SQL code used to create a basic table for storing bank account information in a banking application:\nCREATE TABLE bank_accounts (\n    account_number VARCHAR(100) NOT NULL PRIMARY KEY,\n    account_holder_name VARCHAR(100) NOT NULL,\n    account_balance DECIMAL(10, 2),\n    account_type VARCHAR(50)\n);\n SQL Queries and Relational Algebra \nThe simple SQL queires that we will see all have the form:\nSELECT L\nFROM R\nWHERE C\nin which \\(L\\) is a list of expressions, \\(R\\) is a relation, and \\(C\\) is a condition. The meaning of any such expression is the same as that of the relational algebra epsression\n\\[\n    \\pi_L (\\sigma_C(R))\n\\]\nThat is, we start with the relation in the \\(\\textbf{FROM}\\) clause, apply to each tuple whatever condition is indicated in the \\(\\textbf{WHERE}\\) clause, and then project onto the list of attributes and/or expressions in the \\(\\textbf{SELECT}\\) clause."
  },
  {
    "objectID": "RL/Markov.html",
    "href": "RL/Markov.html",
    "title": "\nMarkov decision process\n",
    "section": "",
    "text": "Markov decision process\n\nJan 19, 2024\n\nThe learner and decisiojn maker is called the agent. In, mathematics a \\(\\textbf{Markov decision process}\\) is a discrete-time stochastic control process. It provides a mathematical framework for modeling decision making in situation where outcomes are partly random and partly under the control of a dicsion maker.\nWe formulate the \\(\\text{MDP}\\) as \\(\\mathcal{M} = (S, A ,P, R, \\gamma)\\)\n\n\\(S\\) is the state space\n\\(A\\) is the action space\n\\(P : S \\times A \\to \\Delta(S)\\) Note: \\(\\Delta(S)\\) is the probability simplex over \\(S\\), i.e., all non-negative vectors of length \\(|S|\\) that sums up to 1\n\\(R: S \\times A \\to \\mathbb{R}\\). Note: A deterministic reward function\n\\(\\gamma \\in [0, 1]\\)\n\nTo formulate my understanding of the above MDP, I can begin to think about it as the agent starts in some state \\(s_1\\), begins with taking action \\(a_1\\), which it then receives a reward \\(r_1 = R(s_1, a_1)\\), transitions to \\(s_2 \\sim P(s_1, a_1)\\), takes action \\(a_2, ...\\) the sequence continues on forever.\nThe objective is the expected total reward or (discounted reward) and in other literature could be refered as the return, value, utility, long-term reward, etc\n\n\\(P(s^\\prime \\mid s, a)\\) The probability of transitiong to a particular state\n\nSometimes the reward is random and/or depends on the next-state. e.g., \\(R(s, a, s^\\prime)\\), or \\(R(s, a)\\) is a random variable. The most general case when given \\((s, a), (r, s^\\prime)\\) is drawn from some joint distribution.\n\n Theory and Methodology \nA MDP makes decisions using information about the system‚Äôs current state, the actions being performed by the agent and the rewards earned based on states and actions.\nThe MDP is made up of multiple fundamental elements: the agent, states, a model, actions, rewards, and a policy. The agent is the object or system being controlled that has to make decisions and perfrom actions. The agent lives in an environmnet that can be decribed using states, which contain information about the agent and the environment. The model determines the rules of the world in which the agent lives, in other words, how certain states and actions lead to other states. The agent can perform fixed set of actions in any given state. The agent receives rewards based on its current state. A policy is a function that determines the agent‚Äôs next action based on its current state.\n MDP Framework: \n\n\\(S \\to\\) States \\((s \\in S)\\)\n\\(A \\to\\) Actions \\((a \\in A)\\)\n\\(P(S_{t + 1} | s_t, a_t) \\to\\) Model determining transition probabilities\n\\(R(s) \\to\\) Reward\n\nIn order to understand how the MDP works, first the Markov Property must be defined. The Markov Property states that the future is independent of the past given the present. In other words, only the present is needed to determine the future, since the present contains all necessary information from the past. The Markov Property can be described in mathematical terms below:\n\\[\n    P[S_{t + 1} | S_t] = P[S_{t + 1} | S_1, S_2, S_3, ..., S_t]\n\\]\nThe above notation conveys that the probability of the next state given current state is equal to the probability of the next state given all previous states. The Markov Property is relevant to the MDP because only the current state is used to determine the next action, the previous states and actions are not needed.\n The Policy and Value Function \nThe policy, \\(\\Pi\\) is a function that maps actions to states. The policy determines which is the optimal action given the current state to achieve the maximum total reward.\n\\[\n    \\Pi : S \\times A\n\\]\nBefore the best policy can be determined, a goal or return must be defined to quantify rewards at every state. There are various ways to define the return. Each variation of the return function tries to maximize rewards in some way, but differs in which accumulation of rewards should be maximized. The first method is to choose the action that maximizes the expected reward given the current state. This is the myopic method, which weighs each time-step decision equally. Next is the finite-horizon method, which tries to maximizes the accumulated reward over a fixed number of time steps. But because many applications may have inifinite horizons, meaning the agent will always have to make decisions and continuously try to maximize its reward, another method is commonly used, known as the infinite-horizon method. In the infinite-horizon method, the goal is to maximize the expected sum of rewards over all steps in the future. When performing an infinite sum of rewards that are all weighed equally, the results may not converge and the policy algorithm may get stuck in a loop. In order to avoid this, and the able prioritize short-term or long term-reawrds, a discount factor, \\(\\gamma\\), is added. If \\(\\gamma\\) is closer to 0, the policy will choose actions that prioritize more immediate reawrds, if \\(\\gamma\\) is closer to 1, long-term rewards are prioritized.\nReturn/Goal Variations:\n\nMyopic: Maximize \\(E[r_t | \\Pi, s_t],\\) maximize expceted reward for each state\nFinite-horizon: Maximize \\(E[\\sum_{t=0}^k r_t | \\Pi, s_t],\\) maximize sum of expected reward over finite horizon\nDiscounted Infinite-horizon: Maximize \\(E[\\sum_{t=0}^\\infty \\gamma^t r_t | \\Pi, s_t] \\quad \\gamma \\in [0, 1]\\), maximize sum of discounted expected reward over infinite horizon\n\nThe value function \\(V(s)\\), characterizes the return at a given state. Most commonly, the discounted infinite horizon return method is used to determined the best policy. Below the value function is defined as the expected sum of discounted future rewards.\n\\[\n    V(s) = E\\left[\\sum^\\infty_{t=0} \\gamma^t r_t | s_t\\right]\n\\]\nThe value function can be decomposed into two parts, the immediate reward of the currrent state, and the discounted value of the next state. This decomposition leads to the derivation of the Bellman Eqaution. Because the actions and rewards are dependent on the policy, the value function of an MDP is associated with a given policy.\n\\[\n    \\begin{align*}\n        V(s) &= E[r_{t + 1} + \\gamma V(s_{t+1}) | s_t], \\quad s_{t+1} = s^\\prime \\\\\n        V(s) &= R(s, \\Pi(s)) + \\gamma \\underset{s^\\prime \\in S} {\\sum} P_{ss^\\prime}V(s^\\prime) \\\\\n        V^\\Pi (s) &= R(s, \\Pi(s)) + \\gamma \\underset{s^\\prime \\in S} {\\sum} P(s^\\prime | s, \\Pi(s)) V(s^\\prime) \\\\\n        V^*(s) &= \\max_a \\left[R(s, a) + \\gamma \\underset{s^\\prime \\in S} {\\sum} P(s^\\prime | s, a) V^*(s^\\prime) \\right]\n    \\end{align*}\n\\]\n\nA Markov decision Processes (MDP) we label as \\(\\mathcal{M} = (S, A, P, R, \\gamma)\\)"
  },
  {
    "objectID": "CS421/lect4.html",
    "href": "CS421/lect4.html",
    "title": "\nRecursion\n",
    "section": "",
    "text": "Recursion\n\nJan 25, 2024\n\nFunctional programmers are defined by their love of recursive functions, and in many ways recursive functions in functional programming are the equivalent of loops in imperative programming. In functional languages, loops are second-class citizens, whlist recursive get all the best support.\nWriting recursive functions requires a change in mindset from writing for loops and while loops, so this section will be just an introduction and a few examples.\nIn the first example, we‚Äôll read the whole file into memory (into a long string). There are essentially three possible approaches to this:\n Approach 1\nGet the length of the file and read it all at once using the really_input method. This is the simplest, but it might not work on channels that are not really files (e.g., reading keyboard input) which is why we have two other approaches.\n Forward Recursion and fold_right, even_count_fr\nOutcome learn more about Forward recursion and how to use fold_right.\n\nWrite a function even_count_fr : int list -&gt; int that returns the number of even integers found in the input list. The function is required to use (only) forward recursion (no other form of recursion). You may not use any library functions or any problems later in this set.\n\nlet rec even_count_fr list = \n    match list with \n    | [] -&gt; 0\n    | (x::xs) -&gt; let count_result = even_count_fr xs in \n    if (x mod 2) = 0 then (1 + count_result) else count_result\n\nWrite a value even_count_fr_base and function even_count_fr_rec : int -&gt; int -&gt; int such that (fun l -&gt; List.fold_right even_count_fr_rec l even_count_fr_base) computes the same results as even_count_fr of the problem above. There should be no use of recursion or library functions in defining even_count_fr_rec.\n\n# let even_count_fr_base = 0;;\nval even_count_fr_base : int = \n# let even_count_fr_rec r x = if (x mod r) = 0 then (1 + x) else x;;\nval even_count_fr_rec : int -&gt; int -&gt; int = &lt;fun&gt;\n# (fun l -&gt; List.fold_right even_count_fr_rec l even_count_fr_base) [1; 2; 3]\n Forward Recursion and fold_right, remove_even \n\nWrite a function remove_even : int list -&gt; int list that returns a list in the same order as the input list, but with all the even numbers removed. The function is required to use (only) forward recursion (no other form of recursion). You may use mod for testing whether an integer is even. You may not use any library functions.\n\nlet rec remove_even list = \n    match list with \n    | [] -&gt; []\n    | (x::xs) -&gt; let result_list = remove_even xs in \n    if (x mod 2) &lt;&gt; 0 then x::result_list else result_list\n\nWrite a value remove_even_base and function remove_even_rec : int -&gt; int list -&gt; int list such that (fun list -&gt; List.fold_right remove_even_rec list remove_even_base) computes the same results as remove_even of the problem above. There should be no use of recursion or library functions in defining remove_even_rec.\n\n# let remove_even_base = []\n  val remove_even_base : ...\n# let remove_even_rec n r = if (n mod 2) &lt;&gt; 0 then n::r else r \n  val remove_even_rec : int -&gt; int list -&gt; int list = &lt;fun&gt; \n# (fun list -&gt; List.fold_right remove_even_rec list remove_even_base) [1; 4; 3; 7; 2; 8];;\n# - : int list = [1; 3; 7] \n Forward Recursion , sift \n\nWrite a function sift : (‚Äôa -&gt; bool) -&gt; ‚Äôa list -&gt; ‚Äôa list * ‚Äôa list such that sift p l returns a pair of lists, the first containing all the elements of l for which p returns true, and the second containing all those for which p returns false. The lists should be in the same order as in the input list. The function is required to use (only) forward recursion (no other form of recursion). You may not use any library functions.\n\nlet rec sift p l = \n    match l with \n    | [] -&gt; ([], [])\n    | (x::xs) -&gt; let (true_list, false_list) = sift p xs in \n    if (p x) then (x::true_list, false_list) else (true_list, x::false_list)\n Forward Recursion, apply_even_odd \n\nWrite a function apply_even_odd : ‚Äôa list -&gt; (‚Äôa -&gt; ‚Äôb) -&gt; (‚Äôa -&gt; ‚Äôb) -&gt; ‚Äôb list such that apply_even_odd [x0; x1; x2; x3; ‚Ä¶] f g returns a list [f x0; g x1; f x2; g x3; ‚Ä¶]. The function is required to use (only) forward recursion (no other form of recursion). You may not use any library functions.\n\nlet rec apply_even_odd l f g = \n    mathch l with \n    | [] -&gt; []\n    | (x::xs) -&gt; match xs with \n                | [] -&gt; [f x]\n                | (h::t) -&gt; (f x::g h::apply_even_odd t f g)"
  },
  {
    "objectID": "CS421/lect3.html",
    "href": "CS421/lect3.html",
    "title": "\nClosures and Evaluation of Function Application, Order of Evaluation in OCaml\n",
    "section": "",
    "text": "Closures and Evaluation of Function Application, Order of Evaluation in OCaml\n\nJan 25, 2024\n\n Functions with more than one argument \n# let add_three x + y + z = x + y + z;;\nval add_three : int -&gt; int -&gt; int -&gt; int = &lt;fun&gt; \n# let t = add_three 6 3 2;;\nval t : int = 11\n# let add_three = \n  fun x -&gt; (fun y -&gt; (fun z -&gt; x + y + z));;\nval add_three : int -&gt; int -&gt; int -&gt; int = &lt;fun&gt;"
  },
  {
    "objectID": "CS421/lect9.html",
    "href": "CS421/lect9.html",
    "title": "\nTerminology: Review\n",
    "section": "",
    "text": "Terminology: Review\n\nFeb 18, 2024 All notes are expanded based on \n\n\n\n\n\n\nA function is in Direct Style when it returns its result back to the caller.\n\n\n\n\nA function is in Continuation Passing Style when it, and every function call in it, passes its result to another function.\n\n\n\nA Tail Call occurs when a funciton returns the result of another fucntion call without any more computations (e.g.¬†tail recursion)\n\n\n\nInstead of returning the result to the caller, we pass it forward to another function giving the computation after the call.\n\n\n\nInstead of returning the result to the caller, we pass it forward to another function giving the computation after the call.\n\n\n\nCPS Transformation\n\n\n\n\nStep 1: Add continuation argument to any function definition:\n\n\n\nLet f arg = e \\(\\Rightarrow\\) let f arg k = e\n\n\nIdea: Every function takes an extra parameter saying where the result goes\n\n\n\nStep 2: A simple expression in tail position should be passed to a continuation instead of returned:\n\n\n\nreturn a \\(\\Rightarrow\\) k a\n\n\nAssuming a is a constant or variable.\n\n\n‚ÄúSimple‚Äù = ‚ÄúNo available function calls.‚Äù\n\n\n\nStep 3: Pass the current continuation to every function call in tail position.\n\n\n\nreturn f arg \\(\\Rightarrow\\) f arg k\n\n\nThe function ‚Äúisn‚Äôt going to return,‚Äù so we need to tell it where to put the result.\n\n\n\nStep 4: Each function call not in tail position needs to be converted to take a new continuation (containing the old continuation as appropriate)\n\n\n\nreturn op (f arg) \\(\\Rightarrow\\) f arg (fun r -&gt; k(op r))\n\n\nop represents a primitive operation\n\n\nreturn g(f arg) \\(\\Rightarrow\\) f arg (fun r -&gt; g r k)\n\n\n\n\nExample\n\n\n\n\n\n\nBefore:\n\n\n\n\nAfter:\n\n\n\n\n\nlet rec add_list lst = \n    match lst with [] -&gt; 0\n    | (0::xs) -&gt; add_list xs \n    | (x::xs) -&gt; (+) x (add_list xs)\n\n\nlet rec add_listk k = \n    match lst with      (* rule 1 *)\n    | [] -&gt; k 0         (* rule 2 *) \n    | (0::xs) -&gt; add_list xs k  (* rule 3 *)\n    | (x::xs) -&gt; add_list xs \n                (fun r -&gt; k ((+) x r))\n                    (* rule 4 *)\n    \n\n\n\n\nExample 2\n\n\n\n\n\n\nBefore:\n\n\n\n\nAfter:\n\n\n\n\n\nlet rec mem (y, lst) = \n    match lst with [] -&gt; false \n    | (x::xs) -&gt; \n        if x = y then \n            true \n        else \n            mem(y, xs)\n\n\nlet rec memk (y, lst) k =\n    match lst with      (* rule 1 *)\n    | [] -&gt; k false  \n    | (x::xs) -&gt;        (* rule 2 *)\n        eqk (x, y)\n        (fun b -&gt; \n            if b then  (* rule 4 *)\n                k true (* rule 2 *)\n            else memk (y, xs) k \n            (* rule 3 *))\n    \n\n\n\n\nData type in Ocaml: lists\n\n\n\n\nFrequently used lists in recursive program\n\n\n\nMatched over two structural cases\n\n\n\n\\(\\textcolor{red}{[ ]}\\) - the empry list\n\n\n\\(\\textcolor{blue}{(\\text{x} \\textcolor{red}{::} \\text{xs})}\\) a non-empty list\n\n\n\nCovers all possibel lists\n\n\n\\(\\textcolor{gold}{\\text{type}} \\textcolor{blue}{ \\text{{`a list}}} = \\textcolor{red}{[]}  \\textcolor{gold}{|} \\textcolor{blue}{(\\textcolor{red}{::} )} \\text{ of } \\textcolor{blue}{\\text{ `a * `a list}}\\)\n\n\n\nNot quite legitimate declaration because of special syntax\n\n\n\n\nVariants - Syntax (slightly simplified)\n\n\n\n\n\\(\\textcolor{gold}{\\text{type}} \\textcolor{blue}{\\text{ name }}  = \\textcolor{red}{C_1} [\\textcolor{gold}{\\text{of }} \\: \\textcolor{blue}{ ty_1}] \\: | \\dots \\: |  \\: \\textcolor{red}{C_n} [\\textcolor{gold}{\\text{of }} \\: \\textcolor{blue}{ ty_n}]\\)\n\n\n\nIntroduce a type called name\n\n\n\\((\\text{fun } -&gt; C_i \\text{ x}) : ty_1 -&gt; \\text{name}\\)\n\n\n\\(C_i\\) is called a constructor; if the optional type argument is omitted, it is called a constant\n\n\nConstructors are the basis of almost all pattern mathcing\n\n\n\nEnumeartion Types as Variants\n\n\nAn enumeration type is a collection of distinct values\n\nIn C and Ocaml they have an order structure; order by order of input\ntype weekday = Monday | Tuesday | Wednesday | Thursday | Friday \n    | Saturday | Sunday \n\nFunctions over Enumerations\n\n\nlet day_after day = match day with \n    Monday -&gt; Tuesday \n    | Tuesday -&gt; Wednesday\n    | Wednesday -&gt; Thursday\n    | Thursday -&gt; Friday \n    | Friday -&gt; Saturday\n    | Saturday -&gt; Sunday\n    | Sunday -&gt; Monday\n\n\nlet rec days_later n day =\n    match n with 0 -&gt; day\n    | _ -&gt; if n &gt; 0 \n            then day_after (days_later (n -1) day)\n            else days_later (n + 7) day\n# days_later 2 Tuesday;;\n- : weekday = Thursday\n# days_later (-1) Wednesday;;\n- : weekday = Tuesday\n# days_later (-4) Monday;;\n- : weekday = Thursday\n\nProblem:\n\n\nWrite a function \\(\\textcolor{blue}{\\text{is\\_weekend : weekday bool}}\\)\nlet is_weekend day =\n    match day with \n    Saturday -&gt; true\n    | Sunday -&gt; true\n    | _ -&gt; false\n\nExample Enumeration Types\n\n\ntype bin_op = IntPlusOp | IntMinusOp\n        | EqOp | CommaOp | ConsOp\n\ntype mon_op = HdOp | TlOp | FstOp\n        | SndOp\nExplanantion of \\(\\textcolor{blue}{\\text{bin\\_op type}}\\)\nWe create a type name bin_op (short for binary operator), which can take one of the following five values:\n\n\n\\(\\textcolor{blue}{\\text{IntPlusOp}}\\) represents an operation for integer addition.\n\n\n\n\\(\\textcolor{blue}{\\text{IntMinusOp}}\\) represents an operation for integer subtraction.\n\n\n\n\\(\\textcolor{blue}{\\text{EqOp}}\\) represents an equality operation.\n\n\n\n\\(\\textcolor{blue}{\\text{CommaOp}}\\) represents a comma operator.\n\n\n\n\\(\\textcolor{blue}{\\text{ConsOp}}\\) represents the cons operation, to construct lists or combine an element with a list.\n\n\nExplanantion of \\(\\textcolor{blue}{\\text{mon\\_op type}}\\)\nWe create a type name mon_op (short for monadic or unary operator), which can take one of the following five values:\n\n\n\\(\\textcolor{blue}{\\text{HdOp}}\\) represents head of list (the first element)\n\n\n\n\\(\\textcolor{blue}{\\text{TlOp}}\\) represents the tail of the list (the last element)\n\n\n\n\\(\\textcolor{blue}{\\text{FstOp}}\\) represents an operation to get the first element of a tuple\n\n\n\n\\(\\textcolor{blue}{\\text{SndOp}}\\) represents an operation to get the second element of a tuple.\n\n\n\n\\(\\textcolor{blue}{\\text{ConsOp}}\\) represents the cons operation, to construct lists or combine an element with a list.\n\n\n\nDisjoint Union Types\n\n\nDisjoint union types, with some possibly occurring more than once\n\nWe can also add in some new singleton elements\ntype id = DriversLicense of int \n    | SocialSecurity of int | Name of string\n\nlet check_id id = match id with \n    DriversLicense num -&gt; \n        not (List.mem num[13570; 99999])\n        | SocialSecurity num -&gt; num &lt; 900000000\n        | Name str -&gt; not (str = \"John Doe\")\n\nProblem:\n\n\nCreate a type to represent the currencies for US, UK, Europe and Japan\ntype currency = \n    Dollar of int \n    | Pound of int \n    | Euro of int\n    | Yen of int\n\nExample Disjoint Union Type\n\n\ntype const = \n    BoolConst of bool\n    | IntConst of int \n    | FloatConst of float \n    | StringConst of float\n    | NilConst \n    | UnitConst\n\ntype const = BoolConst of bool\n    | IntConst of int | FloatConst of float \n    | StringConst of string | NilConst\n    | UnitConst\n\n\nHow do we represnet 7 as a const?\n\n\n\nAnswer: \\(\\textcolor{blue}{\\text{IntConst 7}}\\)\n\n\n\nPolymorphism in Variants\n\n\n\n\nThe type \\(\\textcolor{red}{\\text{`a option}}\\) gives us something to represent non-existence or failure\n\n\ntype `a option = Some of `a | None\n\n\nUsed to encode partial functions\n\n\n\nOften can replace the raising of an exception\n\n\n\nFunctions producing option\n\n\n# let rec first p list = \n    match list with [] -&gt; None \n    | (x::xs) -&gt; if p x then Some x else first p xs\nval first : (`a -&gt; bool) -&gt; `a lost -&gt; a` option = &lt;fun&gt;\n\n# first (fun x -&gt; x &gt; 3) [1;3;4;2;5];;\n- : int option = Some 4\n# first (fun x -&gt; x &gt; 5) [1;3;4;2;5];;\n- : int option = None\n\nFunctions over option\n\n\n# let result_ok r = \n    match r with None -&gt; false\n    | Some _ -&gt; true;;\nval result_ok : `a option -&gt; bool = &lt;fun&gt;\n# result_ok (first (fun x -&gt; x &gt; 3) [1;3;4;2;5]);;\n- : bool = true\n# result_ok (first (fun x -&gt; x &gt; 5) [1;3;4;2;5]);;\n- : bool = false\n\nProblem:\n\n\n\n\nWrite a hd and tl on lists that doesn‚Äôt raise an exception and works at all types of lists.\n\n\nlet hd list = \n    match list with [] -&gt; None\n    | (x::xs) -&gt; Some x\n\nlet tl list = \n    match list with [] -&gt; none\n    | (x::xs) -&gt; Some xs\n\nMapping over Variants\n\n\n# let optionMap f opt = \n    match opt with None -&gt; None\n    | Some x -&gt; Some (f x)\nval optionMap : (`a -&gt; `b) -&gt; `a option -&gt; `b\n    option = &lt;fun&gt;\n# optionMap (fun x -&gt; x - 2)\n    (first (fun x -&gt; x &gt; 3) [1;3;4;2;5]);;\n- : int option = Some 2\n\nFolding over Variants\n\n\n# let optionFold someFun noneVal opt = \n    match opt with None -&gt; noneVal\n    | Some x -&gt; someFun x;;\nval optionFold : (`a -&gt; `b) -&gt; `b -&gt; `a option -&gt; \n    `b = &lt;fun&gt;\n# let optionMap f opt = \n    optionFold (fun x -&gt; Some(f x)) None opt;;\nval optionMap : (`b -&gt; `b) -&gt; `a option -&gt; `b \n    option = &lt;fun&gt;\n\nRecursive Types\n\n\n\n\nThe type being defined may be a component of itself\n\n\n\n\nRecursive Data Types\n\n\ntype int_Bin_Tree = \n    Leaf of int | Node of (int_Bin_Tree * int_Bin_Tree)\n\nRecursive Data Types Values\n\n\nlet bin_tree = \n    Node(Node(Leaf 3, Leaf 6), Leaf(-7))\n\n\nRecursive Functions\n\n\nlet rec first_leaf_value tree = \n    match tree with (Leaf n) -&gt; n\n    | Node (left_tree, right_tree) -&gt; \n    first_leaf_value left_tree\n\n# let left = first_leaf_value bin_tree\nval left : int = 3\n\nRecursive Data Types\n\n\ntype exp = \n    VarExp of string\n    | ConstExp of const\n    | MonOpAppExp of mon_op * exp\n    | BinOpAppExp of bin_op * exo * exp \n    | IfExp of exp * exp * exp \n    | AppExp of exp * exp \n    | FunExp of string * exp\n# type bin_op = IntPlusOp | IntMinusOp | EqOp | CommaOp \n    | ConsOp | ...\n\n# type const = BoolConst of bool | IntConst of int |\n...\n\n# type exp = VarExp of string | ConstExp of const | \n    BinOpAppExp of bin_op * exp * exp | ...\n\n\nHow to represent 6 as an exp?\n\n\n\nAnswer: ConstExp (IntConst 6)\n\n\n\nHow to represent (6, 3) as an exp?\n\n\n\nBinOpAppExp (CommaOp, ConstExp (IntConst 6), ConstExp(IntConst 3))\n\n\n\nHow to represent [(6, 3)] as an exp?\n\n\n\nBinOpAppExp(ConstOp, BinOpAppExp(CommaOp, ConstExp(IntConst 6), ConstExp(IntConst 3)), ConstExp NilConst)\n\n\n\n\nProblem\n\n\ntype int_Bin_Tree = Leaf of int \n    | Node of (int_Bin_Tree * int_Bin_Tree)\n\n\nWrite sum_tree : int_Bin_Tree -&gt; int\n\n\nAdds all ints in tree\nlet rec sum_tree t =\n\n\nlet rec sum_tree t = \n    match t with Leaf n -&gt; n\n    | Node(t1, t2) -&gt; sum_tree t1 + sum_tree t2\n\n\nHow to count the number of variables in an exp?\n\n\nlet rec varCnt exp = \n    match exp with VarExp x -&gt; 1\n    | ConstExp c -&gt; 0 \n    | BinOpAppExp (b, e1, e2) -&gt;  varCnt e1 + varCnt e2\n    | FunExp (x, e) -&gt; 1 + varCnt e\n    | AppExp (e1, e2) -&gt;  varCnt e1 + varCnt e2\n\nMapping over Recursive Types\n\n\nlet rec ibtreeMap f tree = \n    match tree with (Leaf n) -&gt; Leaf (f n)\n    | Node (left_tree, right_tree) -&gt; \n    Node (ibtreeMap f left_tree, ibtreeMap f right_tree)\n\n# ibtreeMap ((+) 2) bin_tree;;\n- : int_Bin_Tree = Node (Node (Leaf 5, Leaf 8), Leaf(-5))\n\nFolding over Recursive Types\n\n\n# let rec ibtreeFoldRight leafFun nodeFun tree = \n    match tree with Leaf n -&gt; leafFun n\n    | Node (left_tree, right_tree) -&gt; \n    nodeFun \n    (ibtreeFoldRight leafFun nodeFun left_tree)\n    (ibtreeFoldRight leafFun nodeFun right_tree);;\nval ibtreeFoldRight : (int -&gt; `a) -&gt; (`a -&gt; `a -&gt; `a) -&gt; \n    int_Bin_Tree -&gt; `a = &lt;fun&gt;\n\n# let tree_sum = \n    ibtreeFoldRight (fun x -&gt; x) (+);;\nval tree_sum : int_Bin_Tree -&gt; int = &lt;fun&gt;\n# tree_sum bin_tree;;\n- : int = 2\n\nMutually Recursive Types\n\n\ntype `a tree = TreeLeaf of `a \n    | TreeNode of `a treeList \nand a` treeList = Last of `a tree\n    | More of (`a tree * `a treeList);;\ntype `a tree = TreeLeaf of `a | TreeNode of `a\n    treeList\nand `a treeList = Last of `a tree | More of (`a \n    tree * `a treeList)\n\nMutually Recursive Types - Values\n\n\nlet tree = \n    TreeNode\n    (More (TreeLeaf 5, \n        More(TreeNode \n            More(TreeLeaf 3, \n                Last(TreeLeaf 2))),\n            Last (TreeLeaf 7)))\n\nA more conventional picture\n\n\nMutually Recursive Functions\n\n\n# let rec fringe tree = \n    match tree with (TreeLeaf x) -&gt; [x]\n    |(TreeNode list) -&gt; list_fringe list\nand list_fringe tree_list = \n    match tree_list with (Last tree) -&gt; fringe tree \n    | (More (tree, list)) -&gt; \n        (fringe tree) @ (list_fringe list);;\n\nval fringe : `a tree -&gt; `a list = &lt;fun&gt; \nval list_fringe : `a treeList -&gt; `a list = &lt;fun&gt; \n\n# fringe tree;;\n- : int list = [5; 3; 2; 7]\n\nProblem\n\n\n# type `a tree = TreeLeaf of `a | TreeNode of `a a treeList \nand `a treeList = Last of `a tree | More of (`a tree * `a treeList);;\n\\(\\textcolor{blue}{\\text{Define tree\\_size}}\\)\nlet rec tree_size t = \n    match t with TreeLeaf _ -&gt; 1\n    | TreeNode ts -&gt; treeList_size ts\nand treeList_size ts = \n    match ts with Last t -&gt; \n    | More t ts` -&gt; tree_size t + treeList_size ts`\n\nNested Recursive Types\n\n\ntype `a labeled_tree =    \n    TreeNode of (`a * `a labeled_tree list)\n\nlet ltree = \n    TreeNode(5, \n    [TreeNode (3, []);\n    TreeNode (2, [TreeNode (1, []);\n            TreeNode (7, [])]);\n    TreeNode (5, [])])"
  },
  {
    "objectID": "probStats/Exam1.html",
    "href": "probStats/Exam1.html",
    "title": "\nExam 1 Review\n",
    "section": "",
    "text": "Exam 1 Review\n\nFeb 21, 2024\n\n\nTopics to cover\n\n\nRandom Variables (from STAT 400) (1.6, 1.7, 1.8, 1.9)\nFunctions of One Random Variable, 1 ‚Äì&gt; 1 (1.6.1, 1.7.1)\nJoint Probability Distributions (2.1)\nIndependent Random Variables (2.5)\nConditional Distributions and Expected Values (2.3)\nFunctions of Two Random Variables, 2 ‚Äì&gt; 1 (2.2)\nTransformations of Two Random Variables, 2 ‚Äì&gt; 2 (2.2)\nOrder Statistics (4.4)\n\n1. Random Variables & Functions of One Random Variable\n\np.d.f. is given as: \\[f_X(x) = \\frac{3}{2000} \\cdot \\sqrt{x}, \\qquad 0 \\leq x \\leq 100, \\qquad \\text{zero elsewhere}\\]\n\\(a)\\) What is the average \\(\\mathbb{E}(X)?\\)\n\\[\n\\begin{align*}\n\\mathbb{E}(X) &= \\int_{0}^{100} x \\cdot \\frac{3}{2000} \\cdot \\sqrt{x} \\:dx \\\\\n              &= \\frac{3}{2000}  \\int_{0}^{100} x \\cdot x^{1/ 2} \\: dx \\\\\n              &= \\frac{3}{2000}  \\int_{0}^{100} x^{3/ 2} \\: dx \\\\\n              &= \\frac{3}{2000} \\cdot \\frac{2}{5} \\left(x^{5/ 2}\\right) \\Bigg |_{0}^{100} \\\\\n              &=  \\frac{3}{2000} \\cdot \\frac{2}{5} \\left(100^{5/ 2}\\right) \\\\\n              &= 60\n\\end{align*}\n\\]\n\\(b)\\) What is the median? That is, find \\(m\\) such that \\(\\text{Pr}(X \\leq m) =\\) \\(\\text{Pr}(X \\geq m) = \\frac{1}{2}\\)\n\\[\n\\begin{align*}\nF_X (m) &= \\text{Pr}(X \\leq m) = \\int_{0}^{m} \\frac{3}{2000} \\cdot \\sqrt{x} \\:dx = \\frac{1}{1000} \\cdot m^{3/2} = \\frac{1}{2} \\\\\n&\\Rightarrow m = 500^{2/3} \\approx 62.996\n\\end{align*}\n\\]\n\\(c)\\) Given a new random variable \\(Y = g(X)\\), where \\(g(X) = 10 \\sqrt{X}\\)\nFind the p.d.f. that describe \\(Y\\).\n\\(y= 10 \\sqrt{x}, \\qquad\\qquad x = \\frac{y^2}{100}, \\qquad\\qquad \\frac{dx}{dy} = \\frac{y}{50}\\)\n\\[\n\\begin{align*}\nf_Y (y) &= \\frac{3}{2000} \\sqrt{  \\frac{y^2}{100}  } \\cdot \\Bigg | \\frac{y}{50} \\Bigg | \\\\\n        &= \\frac{3y^2}{1,000,000} & 0 \\leq y \\leq 100\n\\end{align*}\n\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Improve aesthetics with seaborn\nsns.set(style=\"whitegrid\")\n\n# Define f_X(x) function\ndef f_X(x):\n    return (3/2000) * np.sqrt(x)\n\n# Define f_Y(y) function\ndef f_Y(y):\n    return (3 * y**2) / 1000000\n\n# Generate x and y values within their respective domains\nx_values = np.linspace(0, 100, 400)  # 400 points between 0 and 100\ny_values = np.linspace(0, 100, 400)  # Similarly for y\n\n# Compute PDF values for both functions\nfx_values = f_X(x_values)\nfy_values = f_Y(y_values)\n# Plotting both f_X(x) and f_Y(y) in the same graph for comparison\n\nplt.figure(figsize=(8, 6))\n\n# Plot f_X(x)\nplt.plot(x_values, fx_values, label=r'$f_X(x) = \\frac{3}{2000} \\sqrt{x}$', color='blue')\n\n# Plot f_Y(y)\nplt.plot(y_values, fy_values, label=r'$f_Y(y) = \\frac{3y^2}{1,000,000}$', color='red')\n\nplt.title('PDFs of X and Y')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\n\nplt.show()"
  },
  {
    "objectID": "CS421/lect11.html",
    "href": "CS421/lect11.html",
    "title": "\nTypes and Type Systems\n",
    "section": "",
    "text": "Types and Type Systems\n\nMarch 1, 2024 All notes are expanded based on \n\n\n\n\nWhy Data Types?\n\n\n\n\nData types play a key role in:\n\n\n\n\\(\\textcolor{blue}{\\text{Data abstraction}}\\) in the design of programs\n\n\n\\(\\textcolor{blue}{\\text{Type checking}}\\) in the analysis of programs\n\n\n\\(\\textcolor{blue}{\\text{Compile-time code generation}}\\) in the translation and execution of programs\n\n\nData layout (how many words; which are data and which are pointers) dictated by type\n\n\n\n\nTerminology\n\n\n\n\nType: A \\(\\textcolor{blue}{\\text{type}} \\:\\: \\textcolor{red}{\\text{t}}\\) defines a set of ppssible data values\n\n\n\nE.g. \\(\\textcolor{red}{\\text{short}}\\) in C is \\(\\{x \\mid 2^{15} - 1 \\geq x \\geq -2^{15}\\}\\)\n\n\nA value in this set is said to have type \\(\\textcolor{blue}{t}\\)\n\n\n\n\n\nType system: rules of a language assigning types to expressions\n\n\n\nTypes as Specifications\n\n\n\n\nTypes describe properties\n\n\nDifferent type systems describe different properties, e.g.\n\n\n\nData is read write-versus read-only\n\n\nOperation has authority to access data\n\n\nData came from right source\n\n\nOperation might or could not raise an exception\n\n\n\nCommon type systems focus on types describing same data layout and access methods\n\n\n\nSound Type System\n\n\n\n\nIf an expression is assigned type \\(\\textcolor{red}{\\text{t}}\\), and it evaluates toa value \\(\\textcolor{red}{\\text{v}}\\), then \\(\\textcolor{red}{\\text{v}}\\) is in the set of values defined by \\(\\textcolor{red}{\\text{t}}\\)\n\n\nSML, OCAML, Scheme and Ada have sound type systems\n\n\nMost implementations of C and C++ do not\n\n\n\nStrongly Typed Language\n\n\n\n\nWhen no appliaction of an operator to arguments can lead to a run-time type error, langauge is \\(\\textcolor{red}{\\text{stronly typed}}\\)\n\n\n\nE.g. 1 + 2.3;;\n\n\n\nDepends on definition of type error\n\n\nC++ claimed to be strongly typed, but\n\n\n\nUnion types allow creating a value at one type and using it at another\n\n\nType coercions may cause unexpected (underirable) effects\n\n\nNo array bounds check (in fact, no runtime checks at all)\n\n\n\nSML, OCAML strongly type but still must do dynamic array bounds checks, runtime type case analysis, and other checks\n\n\n\nStatic vs Dynamic Types\n\n\n\n\\(\\textcolor{red}{\\text{Static type}}:\\) type assigned to an expression at compile time\n\\(\\textcolor{red}{\\text{Dynamic type}}:\\) type assigned to a storage location at run time\n\\(\\textcolor{red}{\\text{Statically typed language}}:\\) static type assigned to every expression at compile time\n\\(\\textcolor{red}{\\text{Dynamically typed language}}:\\) type of an expression determined ar run time\n\n\nType Checking\n\n\n\n\nWhen is op(arg1, ‚Ä¶, argn) allowed?\n\n\n\\(\\textcolor{red}{\\text{Type checking}}\\) assures that operations are applied to the right number of arguments of the right types\n\n\n\nRight type may mean same type as was specified, or may mean that there is a predefined implicit coercion that will be applied\n\n\n\nUsed to resolve overloaded operations\n\n\nType checking may be done \\(\\textcolor{red}{\\text{statically}}\\) at compile time or \\(\\textcolor{red}{\\text{dynimically}}\\) at run time\n\n\nDynamically typed (aka untyped) languages (e.g.¬†LISP, Prolog) do only dynamic type checking\n\n\nStatically typed languages can do most typed checking statically\n\n\n\nDynamic Type Checking\n\n\n\n\nPerformed at run-time before each operation is applied\n\n\nTypes of variables and operations left unspecified until run-time\n\n\n\nSame variable may be used at different types\n\n\n\nData object must contain type information\n\n\nErrors aren‚Äôt detected until violating application is execurted (maybe years after the code was written)\n\n\n\nStatic Type Checking\n\n\n\n\nPerformed after parsing, before code generation\n\n\nType of every variable and signature of every operator must be known at compile time\n\n\nCan eliminate need to store type information in data object if no dynamic type checking is needed\n\n\nCatches many programming arrors at earliest point\n\n\nCan‚Äôt check types that depend on dynamically computed values\n\n\n\nE.g. array bounds\n\n\n\nTypically places restriction on languages\n\n\n\nGarbage collection\n\n\nReferences instead of pointers"
  },
  {
    "objectID": "CS421/ocaml.html",
    "href": "CS421/ocaml.html",
    "title": "\nIntroduction to Objective OCaml\n",
    "section": "",
    "text": "Introduction to Objective OCaml\n\nMarch 2, 2024 \n\n\nVariables and Functions\nIn ML, variables are names for values. Variable bindings are bind with the keyword \\(\\text{let}\\).\n\\[ \\text{let identifier = expression}\\]\nDefinitions using \\(\\text{let}\\) can also be nested using the \\(\\text{in}\\) form.\n\\[\n    \\text{let identifier = } \\text{expression}_1 \\text{ in } \\text{expression}_2\n\\]\nThe expression \\(\\text{expression}_2\\) is called the body of the \\(\\text{let}\\) The variable named \\(\\text{identifier}\\) is defined as the value of \\(\\text{expression}_1\\) within the body. The \\(\\text{identifier}\\) is defined only in the body \\(\\text{expression}_2\\) and not \\(\\text{expression}_1\\). A \\(\\text{let}\\) with a body is an expression; the value of a \\(\\text{let}\\) expression is the value of the body.\nFunctions are defined with the keyword \\(\\text{Fun}\\)\n\\[ \\text{fun } v_1 \\quad v_2 \\quad \\cdots\\quad v_n \\rightarrow expression\\]\n\n\nHigher order functions\n\nExercise 3.3:\nWe write a function \\(\\text{sum}\\) that, given two integers bounds n and m and a function f, computes a summation. \\[   \\text{sum n m f } = \\sum_{i=1}^{m} f(i) \\]\nlet sum n m f = \n    if n &gt; m then\n        0\n    else\n        f n + sum (n + 1) m f\n\n\nExercise 3.4:\nEuclid‚Äôs algorithm computes the greatest common divisor (GCD) of two integers.\n\\[\\begin{align*}\n    &\\text{gcd}(n, k) = \\\\\n    &\\quad \\text{while } m \\neq 0 \\\\\n    & \\qquad \\text{if } n &gt; m \\\\\n    & \\qquad \\quad n \\gets n - m \\\\\n    & \\qquad \\text{else} \\\\\n    & \\qquad \\quad m \\gets m - n \\\\\n    &\\quad \\text{return } n\n\\end{align*}\\]\n(* Method 1 *)\nlet rec gcd n m =\n  if m = 0 then n\n  else if n &gt; m then gcd (n - m) m\n  else gcd n (m - n);;\n\n(* Method 2 *)\nlet rec gcd n m =\n  if m = 0 then n\n  else gcd m (n mod m)"
  },
  {
    "objectID": "CS421/ocaml.html#variables-and-functions",
    "href": "CS421/ocaml.html#variables-and-functions",
    "title": "\nIntroduction to Objective OCaml\n",
    "section": "Variables and Functions",
    "text": "Variables and Functions"
  },
  {
    "objectID": "CS421/midterm2.html",
    "href": "CS421/midterm2.html",
    "title": "\nMidterm 2 concepts review\n",
    "section": "",
    "text": "Midterm 2 concepts review\n\nMarch 1, 2024 All notes are expanded based on \n\n\n\n\n MP4\n\n MP4.2: Continuation Passing Style, \\(\\text{quadk}\\)\n\nWrite a function \\(\\text{quadk : int * int * int} \\rightarrow (\\text{int} \\rightarrow \\text{'a}) \\rightarrow \\text{'a}\\) that takes three interger arguments a, b, c and returns the result of the expression \\((2 * (a^2) + 4 * b) + c\\).\n\n# let quadk (a, b, c) k = ...;;\nval quadk : int * int * int -&gt; (int -&gt; `a) -&gt; `a = &lt;fun&gt;\n\n# quadk (1, 1, 1) report_int;;\nResult: 7\n- : unit = ()\nUseful things to know before starting is understanding the way the expression is evaluted when writing the CPS version.\nCommon.ml\nlet mulk(a, b) k = k (a * b);;\nlet addk(a, b) k = k (a + b);;\n\nSolution:\nlet quadk (a, b, c) k =\n    mulk(4, b) (fun e1 -&gt; \n        mulk(a, a) (fun e2 -&gt; \n            mulk(2, e2) (fun e3 -&gt; \n                addk(e2, e2) (fun e4 -&gt; \n                    addk(e4, c) k))))\n\n MP4.3: Continuation Passing Style, \\(\\text{three\\_freeze}\\)\n\nWrite a function \\(\\text{three\\_freezek: string * string} \\rightarrow (\\text{string} \\rightarrow \\text{`a}) \\rightarrow \\text{`a}\\) that takes two strings arguments s and p and calculates the string formed by concatenating them as sp. The function will then return the string made by repeating this string, and then on its left, repeating it once more. In the end, sp wil be repeated three times in a row, but you should only calcualte sp once.\n\n# let three_freezek (s, p) k = ...;;\nval three_freezek : string * string -&gt; (string -&gt; `a) -&gt; `a = &lt;fun&gt;\n\n# three_freezek (\"muda\", \"plop\") (fun s -&gt; (s, String.length s));;\n- : stirng * int = (\"mudaplopmudaplopmudaplop\", 24)\n\n\nSolution:\nlet three_freezek (s, p) k = \n    concatk(s, p) (fun first -&gt; concatk(first, first) (fun second -&gt; concatk(first,second) k))\n  Sample Questions for Midterm 2\n\n 1. Put the following function in full continuation passing style: Use \\(\\text{addk, subk, mulk, leqk, }\\) for the CPS forms of the primitive opeartions (+, -, *, &lt;=). \nlet rec sum_odd n = \n    if n &lt;= 0 then\n        0 \n    else ((2 * n) - 1) + sum_odd (n - 1);;\n\n\nSolution:\nlet sum_oddk n k = \n    leqk (n, 0) (fun is_less -&gt; \n        if is_less k 0 \n        else subk (n, 1) (fun one_less -&gt; \n           sum_oddk one_less (fun e1 -&gt; \n                mulk (2, n) (fun e2 -&gt; \n                    subk (e2, 1) (fun e3 -&gt; \n                        addk (e3, e1) k)))))\n\n2. Given the following OCAML datatype: \\(\\text{type int\\_seq = Null  | Snoc of (int\\_seq * int)}\\) write a tail-recursive function in OCAML all_pos : \\(\\text{int\\_seq}\\rightarrow \\text{bool}\\) that returns true if every integer in the input \\(\\text{int\\_seq}\\) to which all_pos is applied is strictly greater than 0 and false otherwise. Thus \\(\\text{all\\_pos (Snoc(Snoc(Snoc(Null, 3), 5), 7))}\\) should returns true, but \\(\\text{all\\_pos (Snoc(Null, -1))} \\text{ and } \\text{all\\_pos (Snoc(Snoc(Null, 3),0))}\\) should both return false.\n\n\nSolution:\nlet rec all_pos s = \n    (match s with Null -&gt; true\n    | Snoc(seq, x) -&gt; if x &lt;= 0 then false else all_pos seq)\n\n3. Write the definition of an OCAML variant type \\(\\text{reg\\_exp}\\) to express abstract syntax trees for regular expressions over a base character set of booleans. Thus, a boolean is a \\(\\text{reg\\_exp}\\), epsilon is a \\(\\text{reg\\_exp}\\), a paranthesized \\(\\text{reg\\_exp}\\) is a \\(\\text{reg\\_exp}\\), the concatenation of two \\(\\text{reg\\_exp}\\)‚Äôs is a \\(\\text{reg\\_exp}\\), the choice of two \\(\\text{reg\\_exp}\\)‚Äôs is a \\(\\text{reg\\_exp}\\), and the Kleene star of a \\(\\text{reg\\_exp}\\) is a \\(\\text{reg\\_exp}\\). \n\n\nSolution:\ntype reg_exp = \n    Char of bool \n    | Epsilon \n    | Paren of reg_exp\n    | Concat of (reg_exp * reg_exp)\n    | Choice of (reg_exp * reg_exp)\n    | Kleene_star of reg_exp\n\n4. Given the following rules for CPS transformation: \n\\([[x]]_\\kappa = \\kappa \\: x\\)\n\\([[c]]_\\kappa = \\kappa \\: c\\)\n\\([[\\text{let } x = e_1 \\text{ in } e_2]]_\\kappa = [[e_1]] (\\text{FN } x \\rightarrow [[e_2]]_\\kappa)\\)\n\\([[e_1 \\oplus e_2]]_\\kappa = [[e_2]](\\text{FN } a \\rightarrow [[e_1]](\\text{FN } b \\rightarrow \\kappa (b \\oplus a)))\\)\nwhere \\(e_1\\) and \\(e_2\\) are ocaml expressions, \\(\\kappa\\) is any continuation, \\(x\\) is a varibale and \\(c\\) is a constant, give the step-by-step transformation of\n\\[[[\\text{let } x = 2 + 3 \\text{ in } x - 4]] \\text{ REPORTk } \\]\n\nSolution:\n\\([[\\text{let } x = 2 + 3 \\text{ in } x - 4]] \\text{ REPORTk } \\Rightarrow\\)\n\\([[2 + 3]](\\text{FN }x \\rightarrow [[x - 4]] \\text{ REPORTk } ) \\Rightarrow\\)\n\\([[2 + 3]](\\text{FN } x \\rightarrow [[4]](\\text{FN } n \\rightarrow [[x]](\\text{FN } m \\rightarrow \\text{ REPORTk}(m - n)))) \\Rightarrow\\)\n\\([[2 + 3]](\\text{FN } x \\rightarrow [[4]](\\text{FN } n \\rightarrow (\\text{FN } m \\rightarrow \\text{ REPORTk}(m - n)) x)) \\Rightarrow\\)\n\\([[2 + 3]](\\text{FN } x \\rightarrow(\\text{FN } n \\rightarrow (\\text{FN } m \\rightarrow \\text{ REPORTk}(m - n)) x) 4) \\Rightarrow\\)\n\\([[3]](\\text{FN } u \\rightarrow [[2]](\\text{FN } v \\rightarrow (\\text{FN } x \\rightarrow(\\text{FN } n \\rightarrow (\\text{FN } m \\rightarrow \\text{ REPORTk}(m - n)) x) 4)(v + u))) \\Rightarrow\\)\n\\([[3]](\\text{FN } u \\rightarrow (\\text{FN } v \\rightarrow (\\text{FN } x \\rightarrow(\\text{FN } n \\rightarrow (\\text{FN } m \\rightarrow \\text{ REPORTk}(m - n)) x) 4)(v + u)) 2) \\Rightarrow\\)\n\\((\\text{FN } u \\rightarrow (\\text{FN } v \\rightarrow (\\text{FN } x \\rightarrow(\\text{FN } n \\rightarrow (\\text{FN } m \\rightarrow \\text{ REPORTk}(m - n)) x) 4)(v + u)) 2) 3\\)\n\n5. MP5: Continuation Passing Style (CPS) Transformation cps_exp\n\n\nSolution:\nlet rec cps_exp e k = \n    match e with \n    (* [[x]]k = k x *)\n    | VarExp x -&gt; VarCPS (k, x)\n    (* [[c]]k = k c *)\n    | ConstExp c -&gt; ConstCPS (k, c)\n    (* [[~e]]k = [[e]]_(FN v -&gt; k (~v)) *)\n    | MonOpAppExp (m, e) -&gt; \n        let v = freshFor freeVarsInContCPS k \n        in cps_exp e (FnContCPS(v, MonOpAppCPS(k, m, v)))\n    (* [[e1 + e2]]k = [[e2]]_(FN v2 -&gt; [[e1]]_(FN v1 -&gt; k (v1 + v2))) *)\n    | BinOpAppExp (b, e1, e2) -&gt; \n        let v2 = freshFor (freeVarsInContCPS k @ freeVarsInExp e1) in\n        let v1 = freshFor (v2::(freeVarsInContCPS k)) in \n        let cps_e2 = \n            cps_exp e1 (FnContCPS(v1, BinOpAppCPS(k, b, v1, v2))) \n        in cps_exp e2 (FnContCPS(v2, cps_e2))\n    (* [[e1 e2]]k = [[e2]]_(FN v2 -&gt; [[e1]]_(FN v1 -&gt; k (v1, v2))) *)\n    | AppExp (e1 ,e2) -&gt; \n        let v2 = freshFor (freeVarsInContCPS k @ freeVarsInExp e1) in \n        let v2 = freshFor (v2::freeVarsInContCPS k) in \n        let cps_e1 = cps_exp e1 (FnContCPS(v1, AppCPS(k, v1, v2))) in \n        cps_exp e2 (FnContCPS(v2, cps_e1))\n    (* [[fun x -&gt; e]]k = k (FUN x kx -&gt; [[e]]kx) *)\n    | FunExp (x, e) -&gt; \n        let ecps = cps_exp e (ConVarCPS Kvar) in \n        FunCPS(k, x, Kvar, ecps) \n    (* [[let x = e1 in e2]]k = [[e2]]_(FN x -&gt; [[e2]]k) *)\n    | LetInExp (x, e1, e2) -&gt; \n        let e2cps = cps_exp e2 k in \n        let fx = FnContCPS(x, e2cps) in \n        cps_exp e1 fx\n    (* [[let rec f x = e1 in e2]]k = (FN f -&gt; [[e2]]k)(FIX f. FUN x -&gt; FN kx -&gt; [[e1]]kx) *)\n    | LetRecInExp (f, x, e1, e2) -&gt; \n        let e1cps = cps_exp e1 (ContVarCPS Kvar) in \n        let e2cps = cps_exp e2 in \n        FixCPS(FnContCPS(f, kvar), f, x, Kvar, e1cps)\n\n6. Given a polynorphic type derivation for \\(\\{\\} | - \\text{ let id = fun } x \\rightarrow x \\text{ in id id true : bool}\\)\n\n\n\n\\(\\Large\\text{Let }\\frac{ \\text{Fun } \\frac{  \\text{Var }\\frac{}{\\large{{\\{x \\: : \\: 'a \\} \\:\\: \\vdash \\: x \\: : \\: 'a }}}  }{\\large{{\\{\\} \\:\\: \\vdash \\: \\text{ fun } x \\rightarrow \\: x \\:}}} \\quad \\text{App }\\frac{   \\text{App }\\frac{   \\text{Var}\\frac{\\text{Instance : 'a } \\rightarrow \\text{ bool} \\rightarrow \\text{ bool}}{\\large{{\\Gamma  \\:\\: \\vdash \\: \\text{ id : (bool $\\rightarrow$ bool) $\\rightarrow$ bool $\\rightarrow$ bool} }}} \\:\\:  \\text{Var }\\frac{ \\text{Instance : 'a } \\rightarrow \\text{ bool} }{\\large{{\\Gamma  \\:\\: \\vdash \\: \\text{ id : (bool $\\rightarrow$ bool)} }}} }{\\large{{\\Gamma  \\:\\: \\vdash \\: \\text{ id id : bool }  \\rightarrow \\text{ bool} }}}  \\:\\: \\text{Const }\\frac{}{\\large{{\\Gamma  \\:\\: \\vdash \\: \\text{ true : bool } }}}  }{\\large{{\\{\\text{id : } \\forall \\: 'a.'a \\: \\rightarrow \\: 'a\\} \\:\\: \\vdash \\: \\text{ id id true} }}} } {\\large{{\\{\\} \\:\\: \\vdash \\: \\text{let id = fun } x \\rightarrow \\: x \\: : \\: \\text{ in id id true : bool} }}}\\)"
  },
  {
    "objectID": "CS411/dataModels.html",
    "href": "CS411/dataModels.html",
    "title": "\nHigh-Level Database Models\n",
    "section": "",
    "text": "High-Level Database Models\n\nMarch 5, 2024\n\nThe Entity/Relationship Model \n\nEntity sets\nAttributes\nRelationships\n\nEntity Sets\nAn \\(\\text{entity}\\) is an abstract object of some sort, and a collection of similar entities forms an entity set.\nAttributes\nEntity sets have associated \\(\\text{attributes}\\), which are properties of the entities in tha set.\nRelationships\n\\(\\text{Relationships}\\) are connections among two or more entity sets.\nEntity-Relationship Diagrams\nAn E/R diagram is a graph representing entity sets, attributes, and relationships.\n\nEntity sets are represented by rectangles\nAttributes are represented by ovals\nRelationships are represented by diamonds\n\n\nThe Movies entity set has four of our usual attributes: title, year, length, and genre.\n\nStars-in is a relationship connecting each movie to the stars of that movie. This relationship consequently also connecets starts to the movies in which they appeared.\nOwns connects each movie to the studio that owns the movie. The arrow pointing to entity set Studios indicates that each movie is owned by at most one studio.\n\nMultiplicity of Binary E/R Relationships\nA binary relationship can connect any member of one of its entity sets to any number of members of the other entity set. Suppose \\(R\\) is a relationship connecting entity sets \\(E\\) and \\(F\\). Then:\n\nIf each member \\(E\\) can be conncected by \\(R\\) to at most one member of \\(F\\), then we say that \\(R\\) is many-one from \\(E\\) to \\(F\\). Note that in many-one relationship from \\(E\\) to \\(F\\), each entity in \\(F\\) can be connected by to many members of \\(E\\).\nIf \\(R\\) is both many-one from \\(E\\) to \\(F\\) and many-one from \\(F\\) to \\(E\\), then we say that \\(R\\) is one-one. In a one-one relationship an entity of either entity set can be connected to at most one entity of the other set.\nIf \\(R\\) is neither many-one from \\(E\\) to \\(F\\) or from \\(F\\) to \\(E\\), then we say \\(R\\) is many-many.\n\nExample\n\nA one-one realtionship between entity set \\(E\\) and \\(F\\) is represented by arrows pointing to both \\(E\\) and \\(F\\).\n\n\nMultiway Relationships\nA multiway realtionship in an E/R diagram is represented by lines from the relationship diamond to each of the involved entity sets.\n\nUnified Modeling Language (UML)\nUML CLass in UML is similar to an entity set in the E/R model."
  }
]